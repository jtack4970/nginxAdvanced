<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>NGINX - Core</title>

		<meta name="description" content="Learn and practice with NGINX Plus!">
		<meta name="author" content="James Tacker">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/nginx.css" id="theme">

        <!--favicon-->
        <link rel="shortcut icon" href="assets/images/nginxfavicon.ico" type="image/x-icon" />

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

	  <div class="reveal">

        <style>
          .reveal .slides { text-align: left; }
          .reveal .slides h1 { text-align: center; }
          .reveal .slides h2 { text-align: center; }
          .reveal .slides h3 { text-align: center; font-variant: none; text-transform: none;}
        </style>
		<!-- Any section element inside of this container is displayed as a slide -->
		<img src="assets/images/nginxlogo.png" style="border:0; width:100px; height:100px; background:none; position:absolute; left:0; top:0;">
        <img id="lab_pic" src="assets/images/Laboratory3.png" style="visibility:hidden; border:0; width:200px; height:200px; background:none; position:absolute; right:0; top:0;">

        <div class="footer">
          <font size="1">© Copyright 2017 by ServiceRocket, Inc | Confidential | Prepared for NGINX Inc.</font>
        </div>

	        <div class="slides">

              <section data-background="rgb(20, 149, 62)">
                <h1>NGINX CORE</h1>

                <p style="text-align:center">
	              <small><i>Flawless Application Delivery</i></small>
                </p>
              </section>

              <section>
 <!--IF JACOB IS TEACHING-->

		<!--<h3>Trainer Intro</h3>

                    <div style="float:left;width:50%;" class="centered">
                      <p>
                      <strong>Jacob Teal</strong>
                      <p>Technology Consultant</p>
                      <p>B.A. Computational Mathematics</p>
                      <p><a href="mailto:jacob.teal@servicerocket.com">jacob.teal@servicerocket.com</a></p>
					  </p>
                    </div>

                    <div style="float:right;width:40%;padding-right:0px;">
                      <img src="assets/images/starfish.png" style="border:0;background:none; left:0; top:0;">
                    </div>
				</section>

              <section>
                <h3>Course Administration</h3>
                <ul>
                  <li>This session is ~3 hours long</li>
                  <ul><li>10 min. breaks every hour</li></ul>
                  <li>Slides, demonstrations and exercises</li>
                  <li>PDF copy of the materials is available</li>
                  <li>Ask questions at any time</li>
                  <ul><li>Use the chat window</li></ul>
                </ul>
              </section>-->
 <!--IF James IS TEACHING-->
           
              
					<h3>Trainer Intro</h3>

                    <div style="float:left;width:50%;" class="centered">
                      <p>
                      <strong>James Tacker</strong>
                      <p>Technology Consultant & Content Developer</p>
                      <p>Previous Training Work:</p>
                      <ul>
                      	<li>Sauce Labs</li>
                      	<li>New Relic</li>
                      	<li>Salesforce</li>
                      	<li>Atlassian</li>
                      </ul>
                      <p><a href="mailto:james.tacker@servicerocket.com">james.tacker@servicerocket.com</a></p>

					  </p>
                    </div>

                    <div style="float:right;width:40%;padding-right:0px;">
                      <img src="assets/images/Picture1.png" style="border:0;background:none; left:0; top:0;">
                    </div>
				</section>

	      <section>
		<h3>Prerequisites/Expectations</h3>
		<ul>
		  <li>Sysadmin, DevOps, Solution Architect</li>
		  <li>Some familiarity with Web Servers</li>
		  <li>Some familiarity with Linux</li>
		  <li>Text Editor: Vim, Vi, Emacs etc.</li>
		  <li>Some knowledge of Networking</li>
		</ul>
		<aside class="notes">
			<p>This course is designed for those curious about nginx. Maybe you’re a system administrator or developer. </p>
<p>This course is the first step in your roadmap to understanding the ins and outs of NGINX.
This course assumes you have basic Linux command line knowledge as well as how to use a text editor like vim or nano.a
For those of you using Windows, you’ll want to a Linux OS on a virtual machine of your choosing.</p>

		</aside>
	      </section>
	      
              <section>
                <h3>The Training Environment</h3>
		
                <ul>
                  <li>AWS EC2 Instances</li>
                  <li>Ubuntu</li>
                  <li>NGINX Plus</li>
                </ul>
		
                <aside class="notes">
                 
		  
                </aside>
              </section>

	      <section>
		<h3>Log Into AWS</h3>
		<p>If you haven't done so already, please take the time to SSH into your EC2 Instances (Windows users use <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/putty.html" target="_blank">PuTTY</a>).</p>
		<p>Check your email for the login credentials, check your spam folder!</p>
		<pre><code class="linux" data-trim contenteditable>
                        ssh student&#60;number&#62;&#64;&#60;ec2-server-hostname&#62;
                  </code></pre>
	      </section>
	      
	      <section>
		<h3>Course Administration</h3>
		<ul>
			<li>Course Duration: 4 hours</li>
			<li>Takes place over 2 days</li>
			<li>Ask questions at any time!</li>
		</ul>
	      </section>
	      
              <section>
                <h3>Agenda: Part One</h3>

                <div style="text-align:left;">
                    <img src="assets/images/NGINXCoreAgenda1.png" style="border:0;background:none; left:0; top:0;">
                </div>
		
		<aside class="notes">
		<p>So for this first day we're going to cover a general overview of what NGINX is, then we will explore the web server use case and learn about the configuration file, then we will usetup a proxy server, as well as learn about logging. Eventually we will setup our site to use ssl, and then we will round out the day learning about variables</p>

		</aside>
              </section>

		<section>
		  <h3>What is NGINX?</h3>
		  <img src="assets/images/NGINX_Diagram.png" style="border:none; background:none; width:100%">
		  <aside class="notes">
		    <p>NGINX is an open source reverse proxy server. For those who don’t know, a reverse proxy server is a proxy server, sitting behind a firewall in a private network, that directs client requests to appropriate backend servers.</p>
<p>Common uses cases for a reverse proxy server are: Load Balancer, or as I like to call it a web traffic cop, that sits in front of something like apache and distributes client request across a group of servers based on the load they’re handling. HTTP Cache, reverse proxy servers can cache incoming common requests which will speed up the flow of traffic between your clients and servers by reducing the amount of redundant tasks that your backend servers need to manage. Web Server: NGINX can also take over the responsibilities of a web server and host websites that are accessible by the internet.</p>
		  </aside>
		</section>
	      
<!--Adv. Scripts Module-->
              <section data-background="rgb(20, 149, 62)">
                <h2>NGINX Overview</h2>
              </section>

                <section>
                  <h3>Module Objectives</h3>
                  <p>This module enables you to:</p>
                  <ul>
                    <li>Gain a basic understanding of NGINX's features</li>
                    <li>Learn about the history of NGINX</li>
                    <li>Understand the various use cases that NGINX supports</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>

		
			<section>
		  <h3>Origins of NGINX</h3>
		  <div style="float:left;width:50%;" class="centered">
                    <img src="assets/images/Igor.png" style="border:0; background:none; width:100%">
                    </div>
            <div style="float:right;width:50%;padding-right:0px;">        
                    <ul>
                    	<li>2002: <a href="https://www.linkedin.com/in/igorsysoev" target="_blank">Igor Sysov</a> working for rambler.ru</li>
                    	<li>2004: First OSS release</li>
                    	<li>2011: Company founded</li>
                    	<li>2016-Present: 500+ customers and 80+ employees</li>
                    </ul>
                </div>
                  <aside class="notes">
                    <p>NGINX was created by Igor Sysoev in 2002. He was a sysadmin who wasn’t content with the other open source platforms he was working with so he decided to build a better solution that could handle more concurrent users and heavier traffic. He also optimized in such a way that the syntax was simplified and it doesn’t require a lot of memory to run.

                  </aside>
		</section>

		<section>
			<section>
			<h3>High Concurrency</h3>
			<img src="assets/images/High_concurrency.png" style="border:0; background:none; width:100%">
		</section>
		<section>
			<h3>Low Memory</h3>
			<img src="assets/images/low_memory.png" style="border:0; background:none; width:100%">
		</section>
		<section>
			<h3>NGINX Request Processing</h3>
			<ol>
				<li>Translate Request</li>
				<li>Evaluate Configuration</li>
				<li>Select Virtual Server</li>
				<li>Proccess Request</li>
				<li>Serve Response</li>
				<li>Log Connection</li>
			</ol>
                    
                    <aside class="notes">
                      <p>NGINX processes a request in multiple phases, and each phase may contain multiple ”handlers” depending on the type of request.
For example: there are a three separate phases for URI rewrite translation that aren’t mentioned here, and they occur at different times during the lifecycle. Each rewrite phase can contain 3-6 handlers. If you’re interested in the specifics of the phases, as well as the event handler names, checkout NGINX’s source code documentation.

So generally, these are the steps in the request processing life cylce:

<ol>
	<li>Master process translates the request</li>
	<li>Search for a config on file system</li>
	<li>Evaluates configs and selects server to process the request</li>
	<li>server and location contexts will breakdown request into it's smallest parts i.e. the uri and its arguments</li>
	<li>worker will process request and serve response</li>
	<li>nginx lastely will log connection details</li>
</p>
                    </aside>
                </section>

			<section>
		    <h3>NGINX Architecture</h3>
		    <!-- Left Column -->
		     <div style="float:left;width:55%;padding-left:0px;">
		    <img class="fragment" data-fragment-index="0" src="assets/images/EBA_master.png" width="45%" style="position:absolute;top:-100;left:0;" />
		    <img class="fragment" data-fragment-index="1" src="assets/images/EBA_children.png" width="45%" style="position:absolute;top:-100;left:0;" />
		    <img class="fragment" data-fragment-index="2" src="assets/images/EBA_shared.png" width="45%" style="position:absolute;top:-100;left:0;" />
		    <img class="fragment" data-fragment-index="3" src="assets/images/EBA_Cache.png" width="45%" style="position:absolute;top:-100;left:0;" />
		    <img class="fragment" data-fragment-index="4" src="assets/images/EBA_worker.png" width="45%" style="position:absolute;top:-100;left:0;" />

			</div>
		<!--Right Column-->
		<div style="float:right;width:45%;padding-right:0px;">
		  <div class="fragment" data-fragment-index="0" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">Master Process:</span></pre>Evaluates Config</p>
		  </div>
		  
		   <div class="fragment" data-fragment-index="1" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">Child Processes:</span></pre>Adjust module behavior</p>
		  </div>
		  
		   <div class="fragment" data-fragment-index="2" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">Shared Memory:</span></pre>Counters, rate limits, etc.</p>
		  </div>
		  <div class="fragment" data-fragment-index="3" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">Cache Manager and Loader:</span></pre>Cache settings</p>
		  </div>
		  <div class="fragment" data-fragment-index="4" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">Worker Processes:</span></pre>Handle requests and responses</p>
		  </div>
		</div>

		    <aside class="notes">
		      </p>Nginx operates as an EBA system so that it has better performance output. There are a fixed number of threads performing tasks with no new threads being formed.</p>
<p>NGINX runs one master process and several worker processes.  Each worker processes,  can handle thousands of connections. The worker processes accomplish this by implementing a fast looping mechanism that continuously checks for and processes events. Decoupling actual work from connections allows each worker to concern itself with a connection only when a new event has been triggered</p>
<p>The other nice thing about this model is because it uses an event looping mechanism, you don’t have to restart the server to apply changes made to your configuration file. You only need to reload the configuration which will wait for worker processes to finish their tasks, shutdown the worker processes, the master process evaluates the new configuration file, and relays that new information to the worker processes, and the workers begin picking up new tasks</p>
		    </aside>
		</section>	
</section>
		
		<section>
		  <h3>Basic NGINX Commands</h3>
		  <p style="text-align:center;">Below commands can reload, gracefully stop, terminate, or check running config</p>
                  <pre><code class="linux" data-trim contenteditable>
  $ nginx -s reload
$ nginx -s quit
$ nginx -s stop
$ nginx -t
$ nginx -T
                  </code></pre>
                  <aside class="notes">
		    <p>These are the basic commands to run the executable file that loads nginx.
The executable contains an “s” parameter followed by whichever command you’re trying to signal to nginx
The command you we will frequently use is the reload command because changes made in the configuration file will not be applied until nginx is reloaded.</p>

<p>A few important things to remember when shutting down nginx. Using the fast shutdown (nginx -s stop) will kill the master process but NOT wait for the worker processes to finish what they’re doing before killing their processes. On the other hand nginx -s quit will kill the master process and then wait for worker processes to finish their tasks.
</p>
		</aside>
		</section>

		<section>
		  <h3>Reloading the Configuration</h3>
                  <div style="float:left;width:50%;" class="centered">
		    <ol>
		      		<li>SIGHUP signal </li>
                      <li>Master Process evaluates new config</li>
                      <li>Checks for errors</li>
                      <li>Forks new workers while old workers shut down</li>
		    </ol>
		    <p></p>
		  </div>
                  <div style="float:right;width:45%;padding-right:0px;">
                  	<img src="assets/images/reloadConfig.png" width="45%" style="border:none; background:none; width:100%">
		  </div>
		  
		  <aside class="notes">
		    <p>nginx –s reload command sends the master process a SIGHUP signal.</p>
		    <p>The reload command is safe. Worker update is contingent upon lack of syntax errors
Master process then 
forks new set of worker processes to process connections 
signals old worker processes to shutdown gracefully
</p>
		  </aside>
		</section>
		<!--Actions Module-->
              <section data-background="rgb(20, 149, 62)">
                <h2>Serving Static Content</h2>
              </section>
              
              <section>
                  <h3>Module Objectives</h3>
                  <p>This module enables you to:</p>
                  <ul>
                    <li>Understand the Configuration File</li>
                    <li>Configure a Basic Setup</li>
                    <li>Explore server selection methods</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>
		
		  <section>
		    <h3>NGINX Processes</h3>
		    <p>To check running processes, run the following command:</p>
		    <pre><code class="linux" data-trim contenteditable style="text-align:center;">
                      $ ps aux | grep nginx
                    </code></pre>
		    <aside class="notes">
		      <p>Confirm that the EC2 instance has an NGINX master process and at least one worker processes running</p>
		    </aside>
		  </section>
		  <section>
		  <section>
		    <h3>Configuration File</h3>
		    <ul>
		      <p>Global Configuration Path</p>
		      <pre><code class="linux" data-trim contenteditable style="text-align:center;">
                      $ cat /etc/nginx/nginx.conf
                    </code></pre>
		      <p>Additional Configuration(s) Path</p>
		      <pre><code class="linux" data-trim contenteditable style="text-align:center;">
                      $ cat /etc/nginx/conf.d/*.conf
                    </code></pre>
		      <div style="text-align:center;"><small>Documentation: <a href="https://www.nginx.com/resources/wiki/start/topics/examples/full/" target="_blank">nginx.conf Example</a></small></div>
		      
		    </ul>
		    <aside class="notes">
		      <p>The NGINX configuration file is the heart of NGINX. At its highest level, NGINX consists of many modules that are driven by specific directives that we set in the configuration file.
The global configuration is called nginx.conf and lives in the file path /etc/nginx.
Your particular instance of nginx can have one long global configuration file but it can also refer to other...additional configuration files in conf.d directory</p>
		    </aside>
		</section>
		<section>
			<h3>Include Directive</h3>
			<p>The following line in nginx.conf allows NGINX to search for additional configurations</p>
			<pre><code class="linux" data-trim contenteditable style="text-align:center;">
                      include /etc/nginx/conf.d/*.conf;
                    </code></pre>
		</section>
	</section>
	<section>
			<section>
			<h3>Configuration File Structure</h3>
			<ul>
				<li>Directives</li>
				<li>Blocks</li>
				<li>Contexts</li>
			</ul>
			<div style="text-align:center;"><small>Documentation: <a href="http://nginx.org/en/docs/beginners_guide.html#conf_structure" target="_blank">How .conf Files Work</a></small></div>
			<aside class="notes">
				<p>In its basic form a configuration file consists of any combination of directives, blocks, and contexts.</p>
			</aside>
		</section>
		<section>
			<h3>Directives</h3>
			<p>Configuration statement that controls <a href="https://cdn.wp.nginx.com/wp-content/uploads/2016/05/nginx-modules-reference-r9.pdf" target="_blank">NGINX Modules</a></p>
			<pre><code class="linux" data-trim contenteditable style="text-align:left;">
      
      listen 80;
root /usr/share/nginx/html;
index index.html index.htm index.php;
  
                    </code></pre>
                </section>
                <section>
                	<h3>Blocks</h3>
                	<p>Contains mixture of directives and data—begins and ends with curly brackets.</p>
                	<pre><code class="linux" data-trim contenteditable style="text-align:left;">
                	server {
      listen 80;
      root /usr/share/nginx/html;
      index index.html index.htm index.php;
  }
  			</code></pre>
            </section>
		  <section>
		  	<h3>Contexts</h3>
		  	<p>Nested Blocks implying a hierarchy. Colloquially, 'Block' and 'Context' are interchangeable.</p>
		  	<pre><code class="linux" data-trim contenteditable style="text-align:left;">
		  		http {
	include       /etc/nginx/mime.types;
    	default_type  application/octet-stream;
	gzip on;
	log_format

	server {
      		listen 80;
      		root /usr/share/nginx/html;
      		index index.html index.htm index.php;

      		location {
      			proxy_pass http://backend;
      		}
  	}
}
</code></pre>
<div style="text-align:center;"><small>Documentation: <a href="https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts" target="_blank">Further Explanation</a></small></div>
		  </section>
		</section>
		  	<section>
		  	<h3>Serving Content</h3>
		  	<p>Requirements:</p>
		  	<ul>
		  		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 32px;">HTTP Block</span></pre>—Handles high level processing (logging, compression, caching etc.)</li>
		  		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 32px;">Server Block</span></pre>—Virtual Server (Host) that handles the request</li>
		  		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 32px;">Location Block</span></pre>—Further processing based on the URI of the request</li>
		  	</ul>
            
		  	<aside class="notes">
		  		
		  			So how does it work? The combination of these two directives allow nginx to serve file such as images or html pages based on where we put them on our machines. (Go back to previous slide and highlight based on what you talk about below):
		  			<ul>
					<li>The http block will
					<li>server context is where nginx responds to specific requests. Each server context represents an individual virtual server and within it is usually many location blocks referencing location contexts to serve the content.</li>
<li>location context: the context we will deal with most regularly shares many qualities with server context but breaks up the requested IP/port/header combination by handling the requests based on request URI—which is usually the bit that comes after the domain name.</li>
</ul>
	</aside>
		</section>
		<section>
			<h3>Server Block Example</h3>
                  <pre>
                    <code class="linux" data-trim contenteditable>
                      server {
    listen 80;
    server_name www.example.com;
    root /etc/student1/public_html;
}

                    </code>
                  </pre>
                  <aside class="notes">
                  	<p>We need to specify a server block to define our configurations for our virtual servers.
It’s always nested inside of an http context which can contain many server blocks to handle separate subsets of incoming connections.</p>
<p>We can have more than server block, and you most likely will need one if you have a large company serving a lot of content. Nginx decides which server is needed based on the details of the request—which are decided by:
listen port and server_name </p>
<p>Listen directive refers to the ip address and port combination that this server is designated to, so if the request matches these values it will potentially be selected as the server to handle the connection
Server_Name directive is the other way nginx will decide which server to use. Nginx will parse the host header of the request and match it against whatever we wrote here.</p>
<p>For those of you coming from an Apache background this is similar to VirtualHost.</p>

</aside>
              </section>
              <section>
              	<section>
            <h3>Location Block Example</h3>
                  <pre>
                    <code class="linux" data-trim contenteditable>
                      location /application1 {
}
                    </code>
                  </pre>
                  <p>Two most common types of locations:</p>
                  <ul>
                  	<li><strong>Prefix</strong></li>
                  	<li><strong>Regex</strong></li>
                  </ul>

                  <aside class="notes">
                  	<p>Once NGINX has chosen which server to respond with, it then checks the location block to work out what configuration to apply, based on the URI of the request</p>

<p>If you put a root directive in a location block it will override the root directive in the server block. You can nest them but be careful it can get messy.</p>
<p>There are basically TWO TYPES of LOCATION BLOCKS: <strong>Prefix and Regex</strong></p>


                  </aside>
		</section>
		<section>
			<h3>Prefix Location</h3>
			<p>Always checked first, and NGINX selects and remembers longest match</p>
                  <pre>
                    <code class="linux" data-trim contenteditable>
                      location /application1 {

}

location /application1/images {
	alias /media/data;
}

                    </code>
                  </pre>
			<p>Second location is selected and matched if given request: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 32px;">http://somedomain.com/application1/images/?img2</span></pre></p>
			<aside class="notes">
				<ul>
					<p>Prefix locations are always checked first
NGINX will always select and remember the longest matching location prefix
Example: we have a request to http://<server>/application1/images/and then the name or argument of our image. In this example below NGINX will check the first location block for an exact match against an empty string, which won’t work because there isn’t an empty string. So then NGINX checks the second location block and here we have a match in appliation1, but it will continue checking and it sees that the third location block has an even more precise match. So the third location is selected and remembered.</p>
			</aside>
	</section>
	<section>
		<h3>Location Modifiers</h3>
		<ul>
			<li>Exact String Match <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 32px;">=</span></pre> </li>
			<li>Case Insensitive Regex <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 32px;">~*</span></pre></li>
			<li>Case Sensitive Regex <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 32px;">~</span></pre></li>
			<li>Stop Request Processing <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 32px;">^~</span></pre></li>
			<li>Named Location Routing <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 32px;">@</span></pre></li>
		</ul>
		<aside class="notes">
			
			<p>=: If an equal sign is used, this block will be considered a match if the request URI exactly matches the location given.
~: If a tilde modifier is present, this location will be interpreted as a case-sensitive regular expression match.
~*: If a tilde and asterisk modifier is used, the location block will be interpreted as a case-insensitive regular expression match.
^~: If a carat and tilde modifier is present, and if this block is selected as the best non-regular expression match, regular expression matching will not take place.
@: prefix defines a named location. Such a location is not used for a regular request processing, but instead used for request redirection. They cannot be nested, and cannot contain nested locations. Usually used in conjunction with the try_files or error_page directive
</p>
		</aside>
</section>
<section>
	<h3>Regex Location</h3>
	<p>Matched sequentially and only after prefix locations.</p>
	<pre>
                    <code class="linux" data-trim contenteditable>
                      location /application1 {

}

location ~* ^\.(gif|jpg|jpeg|png)$ {
	alias /media/data;
}

                    </code>
                  </pre>
		<aside class="notes">
		<p>Matched after prefix location and are matched in the order they appear, so even if there’s a regex location in between two prefix locations in your configuration file it will still be matched after NGINX has checked all prefix locations with conventional strings before moving on to the regex location.
Case insensitive matching is represented by a tilde and asterisk
Case sensitive matching is represented by a tilde

So in this example we have a location block with insensitive case matching for any character before a dot, followed by the following file extension names.</p>
<p>Note that the ^ symbol in this case is part of the native regular expression symbolism, and is not related to location modifiers</p>
</aside>
</section>
</section>
<section>
	<h3>Location Order</h3>
	<!--Left Column-->
		<div style="float:left;width:50%;padding-left:0px;">
			<p>Configuration Example</p>
			<pre>
                    <code class="linux" data-trim contenteditable>
                     server {
    listen 80 default_server;
    root /usr/share/nginx/html;

    location = / {	
    }

    location ~* ^\.(png|jpg)$ {
    }
	
    location ^~ /app1 {
    }
}
                    </code>
                  </pre>
		  
		  </div>
	<!--Right Column-->
		<div style="float:right;width:45%;padding-right:0px;">
			<p>Selection Order:</p>
			<ul>
		  <div class="fragment" data-fragment-index="0" style="vertical-align:right; margin-left: auto; margin-right: auto;"> <li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location = / {
</span></pre></li></div>
<div class="fragment" data-fragment-index="1" style="vertical-align:right; margin-left: auto; margin-right: auto;"> <li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location ^~ /app1 {
</span></pre></li></div>
<div class="fragment" data-fragment-index="2" style="vertical-align:right; margin-left: auto; margin-right: auto;"> <li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location ~* ^\.(png|jpg)$ {

</span></pre></li></div>
</ul>
		  </div>
	
<aside class="notes">
	<ul>
	<li>Directive with = and an actual string match, the searching stops after literal match. It will search through the rest of the prefix location blocks, but if it finds a match with the carrot tilde parameter, the searching will stop.</li> 
<li>If it doesn’t find any match in the prefix location then it will go to the regex location blocks.</li> 
<li>If it doesn’t find additional matches there, then it will go back to the longest prefix matching location.</li>
</ul>
<p>If #2 yielded a match, that result is used. Otherwise, the match from #3 is used.</p>

</aside>
</section>

<section>
	<section>
		  <h3>Defining Server Names</h3>
		  <pre>
                    <code class="linux" data-trim contenteditable>
                     server {
    server_name mycompany.com *.mycompany.com;
}

server {
    server_name mycompany.net *.mycompany.net;
}
                    </code>
                  </pre>
		  
		  <aside class="notes">
		  	<p>Multiple server names can be useful for situations where you would serve mobile content or localized content within the same server</p>

<p>Defining Server Names</p>
<p>We use the server_name directive to define which server is to respond to a given request. For this is example, your organization would put the company’s domain name following the server_name directive.
It’s possible to define many server names, and in addition to using exact name matching, we can also define servers using wildcards check this for accuracy: regular expressions.
http://nginx.org/en/docs/http/ngx_http_core_module.html#server_name
In this example it will search for anything ending in the host name: example.org, before going on to the location directives to search for matching URI requests.
</p>
		    <p>The server name is checked against the ”host” header field of the incoming HTTP request
This is based on the HTTP host header when the user types in their host name and not on the interface on which we receive the request</p>

		  </aside>
		</section>
		<section>
			<h3>Default Server</h3>
			<pre><code class="linux" data-trim contenteditable>
                     server {
    listen  80 default_server;
    server_name example.net www.example.net;
}

                    </code>
                  </pre>

		<aside class="notes"><p>You can actually set the default server with the default_server parameter on the listen directive.</p>
<p>The parameter checks against the HTTP request header “HOST” field and for each request that doesn’t match any of the hostnames defined in our server_name parameter, it will route the location to the server for the port.
The reason it’s on the listen directive is because NGINX checks the listen port first before it attempts to match the host header against the server name.</p>
</aside>
		</section>
		<section>
			<h3>IP vs. Server_Name</h3>
			<pre><code class="linux" data-trim contenteditable>
                     server {	
    listen  192.168.1.1:80;
    server_name example.org www.example.org;
}

server {
    listen  192.168.1.1:80;
    server_name example.net www.example.net;
}

server {
    listen  192.168.1.2:80;
    server_name example.com www.example.com;
}
                    </code>
                  </pre>
                  <aside class="notes">
<p>In this configuration, NGINX first tests the IP address and port of the request against the listen directives of the server blocks. It then tests the “Host” header field of the request against the server_name entries of the server blocks that matched the IP address and port. </p>
<p>If the server name is not found, the request will be processed by the default server. For example, a request for www.example.com received on the 192.168.1.1:80 port will be handled by the default server of the 192.168.1.1:80 port, i.e., by the first server, since there is no www.example.com defined for this port. You may be asking, why does it serve the response from the top server even though there is no default_server specified on the listen port? THat's because NGINX sets the server at the top of configuration file as the default default_server until one is otherwise specified, that way no connections are dropped</p>
                  </aside>
	</section>
	<section>
		<h3>Bad Requests</h3>
		<p>Use empty string for server_name directive to prevent bad requests</p>
		<pre><code class="linux" data-trim contenteditable>
                     server {
    listen  80;
    server_name "";
    return 444;
}
                    </code>
                  </pre>
                  <aside class="notes"><p>If requests without the “Host” header field should not be allowed, a server that just drops the requests can be defined:</p>

<p>Here, the server name is set to an empty string that will match requests without the “Host” header field, and a special NGINX’s non-standard code 444 is returned that closes the connection.</p>

<p>Since version 0.8.48, this is the default setting for the server name, so the server_name "" can be omitted. In earlier versions, the machine’s hostname was used as a default server name.</p>	
</aside>
              </section>
      </section>
		<section data-state="lab">
		  <h3>Lab 1: Serve Pages and Images</h3>
		  <ol>
		    <li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx/conf.d</pre> and backup <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">default.conf</span></pre>.</li>
		    <li>Create a new configuration called <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server1.conf</span></pre>.</li>
		    <li>Create a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre> listening on port <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">80</span></pre> and a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">root</span></pre> directive of <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/home/student1/public_html</span></pre></li>
		   	<li>Add three <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location</span></pre> prefixes for:
		   		<ul>
		   			<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/application1</span></pre></li><li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/application2</span></pre></li>
		   			<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/images</span></pre></li>
		   		</ul>
		   	</li>
		   	<li>In <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/images</span></pre> prefix, add <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">root /data;</span></pre></li>
		   	<li>Close and save the configuration. Then reload NGINX.</li>
		    <li>Test your EC2 url with the following URIs <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/application1</span></pre>, <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/application2</span></pre>, and <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/images/logo.png</span></pre> What do you observe?</li>
		  </ol>
		  <aside class ="notes">
		  	<ol>
		  	<li>Open /etc/nginx/conf.d and rename the default.conf to default.conf.bak</li>
<li>Create a file called server1.conf in the conf.d folder in /etc/nginx</li>
<li>Add two location blocks that match requests for /application1 and /application2</li>
<li>Add a third location block that matches requests for /images</li>
<li>Override the root directive in the /images location block to specify the folder where your images are stored (i.e /data/images)</li>
<li>Open your browser to your server’s URL. What can you observe?</li>
<li>Now open (server)/application1/app1.html. What can you observe?</li>
<li>Now hit (server)/images/logo.png What can you observe?</li>

</aside>

		</section>

<!--Next Section-->

		<section data-background="rgb(20, 149, 62)">
                  <h2>Proxying Connections</h2>
                 </section>

		<section>
                  <h3>Module Objectives</h3>
                  <p>This module enables you to:</p>
                  <ul>
                    <li>Configure Proxy Server</li>
                    <li>Understand how Proxy Buffering works</li>
                    <li>Demonstrate use of <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_pass</span></pre> directive</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>

    <section>
		<h3>Reverse Proxy Servers</h3>
		<p>Receives requests, passes them to backend servers</p>
		<p>NGINX supports proxy for HTTP, HTTPS, TCP, UDP, and <a href="https://www.nginx.com/resources/admin-guide/reverse-proxy/" target="_blank">other protocols.</a></p>
		<pre><code class="linux" data-trim contenteditable>
                     server {
    listen  80;
    server_name mydomain.com;

    location / {
    	proxy_pass http://backend;
	}
}
                    </code>
                  </pre>
                  <aside class="notes">
<p>So first off, what's the difference between a proxy and reverse proxy? Well, to start the word proxy means to act on behalf of something else. </p>
<p>So if I was your proxy to a meeting, I would represent you and be responbile for relaying any information obtained at the meeting.</p>
<p>In terms of web servers, a <strong>reverse proxy</strong> is mostly a server-side idea, usually used in the context of CDNs (content distribution networks) for caching static HTTP content and passing dynamic content onto the application servers. </p>
</p>A proxy, also colloquilly referred to as "forward proxy" is usually a client side concept used for anonymity, to subvert censorship, and (back in the days of dial-up) as a web accelerator. The idea here is that the proxy event in this case is that the "forward proxy" retrieves data from another web site on behalf of the original requestee.</p>
                  	<p>NGINX's use case is as a reverse proxy. So you can proxy requests to other servers or the same server 
On the server which acts as a proxy, use the proxy_pass directive to pass requests to the proxied server
</p>

<p>Setting up a proxy server is one of the most frequent uses of NGINX and is a good way to increase your webpages’ performance by redirecting requests for new content to other servers and serving familiar requests directly to the client.  To set up one of your servers as a proxy server we include the proxy_pass directive.
</p>	
</aside>
  </section>

  <section>
		<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">proxy_pass</pre> Directive</h3>
		<p>Sets the address, and protocol, of the proxied server(s)</p>
		<p>Syntax:<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_pass <i>url</i></span></pre></pr>
		<p>Example:
		<pre><code class="linux" data-trim contenteditable>
    location / {
    	proxy_pass http://backend:8080/application/;
}
                    </code></pre></p>
		<aside class="notes">
<p>This directive is mainly found in the location context and sets the address for the server we want to pass our requests to.</p>
<p>
When a request matches a location with a proxy_pass directive in it, the request is then forwarded to the address with the URL specified in the directive.</p>
<p>
The URL can be a domain name or an IP address or a server group. Can also contain a path and a port number as seen in the example</p>

		</aside>

  </section>

 <section>
	<h3>Proxy With/Without a Path</h3>
	<h4>With a Path</h4>
	<pre><code class="linux" data-trim contenteditable>
location /application1 {
    proxy_pass http://localhost:8080/otherapp/;
}
	</code></pre>
	<h4>Without a Path</h4>
	<pre><code class="linux" data-trim contenteditable>
location /application2 {
    proxy_pass http://localhost:8080
}
	</code></pre>
	<aside class="notes">
<p>With a Path</p>
<ul>
	<li>Any request matching the location prefix is rewritten to replace the matched portion of the request’s URI, including the location prefix, with the proxy_pass URI. </li>
<li>In the  example, a request to http://server/application1/app1.html will be proxied to http://server:8080/otherapp/app1.html </li>
</ul>
<p>Without a Path</p>
<ul>
	<li>Any request matching the location prefix is rewritten to replace the matched portion of the request’s URI, NOT including the location prefix, with the proxy_pass URI. </li>
<li>In the below example, a request to http://server/application2/app2.html will be proxied to http://server:8080/application2/app2.html 
</li>
</ul>
	</aside>

</section>

<section>
	<h3>Proxy Scenario</h3>
	<pre><code class="linux" data-trim contenteditable>
server {
    listen 80;
    root /home/student1/public_html;

	location / {
	    proxy_pass http://localhost:8080;
	}

	location /application1 {
	    proxy_pass http://localhost:8080/sampleApp/;
	}

	location /images {
	    root /data;
	}
}

server {
    listen 8080;
    root /data/proxy;
}
	</code></pre>
	<aside class="notes">
		<ul>
		<li>http://server is proxied to http://server:8080.
Will load the index.html page in /data/proxy</li>
<li>http://server/test is proxied to http://server:8080/test  
Will load the index.html page in /data/proxy/test</li>
<li>http://server/application1 is proxied to http://server:8080/sampleapp
Will load the index.html page in /data/proxy/sampleapp</li>
<li>http://server/images is not proxied and will load content from /data/images</li>
</ul>

	</aside>
</section>

		<section data-state="lab">
		  <h3>Lab 2: Setup a Reverse Proxy</h3>
		  <ol>
		    <li>Create a new configuration file called <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server2.conf</span></pre> inside <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx/conf.d</span></pre></li>
		    <li>Define a server context that listens on port <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">90</span></pre> and has a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">root</span></pre> directive pointing to <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/data/server2</span></pre></li>
		    <li>Open <strong>server1.conf</strong> from the previous exercise and modify the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/application1</span></pre> context by adding a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_pass</span></pre> with the URI: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">http://localhost:90/sampleApp/</span></pre></li>
		   	<li>Save and Reload NGINX</li>
		    <li>Open your browser and test your server url/application1. What do you see?</li>
		  </ol>
		  <aside class ="notes">
		  	<ol>
		  	<li>cd</li> 
<li>cd /etc/nginx/conf.d</li>
<li>sudo vim server2.conf</li>
<li><pre><code class="linux" data-trim contenteditable>server {
   listen 8008;
 root /data/server2;
}</code></pre></li>
<li>sudo vim server1.conf</li>
<li><pre><code class="linux" data-trim contenteditable>server {
 root /home/student1/public_html;
 location /application1 {
   proxy_pass http://localhost:8080/sampleApp/;
  }
 location /images {
 root /data;
 }</code></pre></li>
<li>Reload nginx.</li>
<li>Test server/application1</li>
</ol>

<p>Explain why the client isn’t seeing /sampleApp in their URI because we used a url path in our proxy pass directive, it overrides the prefix location and sends the requests to /data/sever2 with our sample app folder but it’s not reflected in the client’s browser.</p>


</aside>

		</section>

<section>
	<h3>Proxy Buffers</h3>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_buffering <i>on | off</i></span></pre> sets proxy buffering</li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_buffers <i>number size</i></span></pre>  sets amount and size used for reading entire response for one connection</li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_buffer_size</span></pre>  sets size for reading first part of a response (usually response headers) received from proxied server
</li>
	</ul>
	<aside class="notes">
		<p>Use Cases</p>
<p>You can enable proxy buffering when you wish to buffer information that you pass to your upstream as to not overload your upstream servers, and subsequently place queued responses in a buffer queue. </p>
<ul><li>proxy_buffering: This directive controls whether buffering for this context and child contexts is enabled. By default, this is "on".</li>
<li>proxy_buffers: This directive controls the number (first argument) and size (second argument) of buffers for proxied responses. The default is to configure 8 buffers of a size equal to one memory page (either 4k or 8k). Increasing the number of buffers can allow you to buffer more information.</li>
<li>proxy_buffer_size: The initial portion of the response from a backend server, which contains headers, is buffered separately from the rest of the response. This directive sets the size of the buffer for this portion of the response. By default, this will be the same size as proxy_buffers, but since this is used for header information, this can usually be set to a lower value.</li>
</ul>
</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">proxy_busy_buffers</pre></h3>
	<p>This directive sets max size of “client-ready” buffers.</p>
<p>The “client-ready” buffers are then placed in a queue.</p>
<aside class="notes">This directive sets the maximum size of buffers that can be marked "client-ready" and thus busy. While a client can only read the data from one buffer at a time, buffers are placed in a queue to send to the client in bunches. This directive controls the size of the buffer space allowed to be in this state.
</aside>
</section>

<section>
	<h3>Proxy Busy Buffers Example</h3>
	<pre><code class="linux" data-trim contenteditable>
	server {
    proxy_buffering on; 
    proxy_buffer_size 1k; 
    proxy_buffers 24 4k; 
    proxy_busy_buffers_size 8k; 
    proxy_max_temp_file_size 2048m; 
    proxy_temp_file_write_size 32k; 

	location / { 
	    proxy_pass http://example.com;
	}
}

</code></pre>
<aside class="notes">In the example, this configuration increases the number of available proxy buffers for each upstream request, while trimming down the buffer that likely stores the headers:
</aside>
</section>

 <!--Next Section-->
		<section data-background="rgb(20, 149, 62)">
                  <h2>Logging</h2>
                 </section>

         <section>
                  <h3>Module Objectives</h3>
                  <p>This module enables you to:</p>
                  <ul>
                    <li>Setup Logging to audit connections to NGINX</li>
                    <li>Demonstrate use cases for log levels</li>
                    <li>Differentiate between access and error log</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>

                <section>
                	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">error_log</pre> Directive</h3>
                	<ul>
                		<li>Configures the logging settings for error messages</li>
                		<li>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">error_log <i>file</i> <i>log_level</i></pre></li>
                		<li>"Log Level" specifies the detail of the output</li>
                	</ul>
                	<aside class="notes"><p>Logging is a good way to see what’s going on, and using the error-log directive can configure what gets logged and where.</p> <p>It can be used in the main, server, http, and location contexts. The log level will specify how detailed the log will actually be.
</p>
<p>Can be used in the main, http, and server context</p>
</aside>
                </section>

                <section>
                	<h3>Log Levels</h3>
                	<div style="float:left;width:50%;padding-left:10px;">
                		<div class="fragment" data-fragment-index="0" style="vertical-align:right; margin-right: auto; margin-right: auto;"><p><pre style="display:inline; color:rgb(5,144,57);"><span style="font-size: 30px;">debug</span></pre></p></div>

                		<div class="fragment" data-fragment-index="1" style="vertical-align:right; margin-right: auto; margin-right: auto;"><p><pre style="display:inline; color:rgb(255,255,255);"><span style="font-size: 30px;">info</span></pre></p></div>

                		<div class="fragment" data-fragment-index="2" style="vertical-align:right; margin-right: auto; margin-right: auto;"><p><pre style="display:inline; color:rgb(255,255,255);"><span style="font-size: 30px;">notice</span></pre></p></div>

                		<div class="fragment" data-fragment-index="3" style="vertical-align:right; margin-right: auto; margin-right: auto;"><p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">warn</span></pre></p></div>

                		<div class="fragment" data-fragment-index="4" style="vertical-align:right; margin-right: auto; margin-right: auto;"><p><pre style="display:inline; color:rgb(255,94,0);"><span style="font-size: 30px;">error</span></pre></p></div>

                		<div class="fragment" data-fragment-index="5" style="vertical-align:right; margin-right: auto; margin-right: auto;"><p><pre style="display:inline; color:rgb(218,41,28);"><span style="font-size: 30px;">crit</span></pre></p></div>

                		<div class="fragment" data-fragment-index="6" style="vertical-align:right; margin-right: auto; margin-right: auto;"><p><pre style="display:inline; color:rgb(218,41,28);"><span style="font-size: 30px;">alert</span></pre></p></div>

                		<div class="fragment" data-fragment-index="7" style="vertical-align:right; margin-right: auto; margin-right: auto;"><p><pre style="display:inline; color:rgb(218,41,28);"><span style="font-size: 30px;">emerg</span></pre></p></div>
                	
                </div>
                	<div style="float:right;width:40%;padding-right:0px;">
		  <div class="fragment" data-fragment-index="0" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p>Detailed Trace</p>
		  </div>
		  	<div class="fragment" data-fragment-index="1" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p>General Info</p>
		  </div>
		  <div class="fragment" data-fragment-index="2" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p>Something Normal</p>
		  </div>
		  <div class="fragment" data-fragment-index="3" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p>Something Strange</p>
		  </div>
		  <div class="fragment" data-fragment-index="4" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p>Unsuccessful</p>
		  </div>
		  <div class="fragment" data-fragment-index="5" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p>Important Issue(s)</p>
		  </div>
		  <div class="fragment" data-fragment-index="6" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p>Fix Now!</p>
		  </div>
		  <div class="fragment" data-fragment-index="7" style="vertical-align:right; margin-right: auto; margin-right: auto;"> <p>Unusable</p>
		  </div>
		</div>
                	<aside class="notes"><p>Log output includes all messages from the specified level and all other levels which are more severe
</p>

<p>Here is a list of possible levels from most mundane to most severe.
</p>
<ul>
<li>Debug:  used to pinpoint problems</li>
<li>Info: used to convey general information about processes</li>
<li>Notice:Something normal occuring, possibly a handshake or other transaction</li>
<li>Warn:Something out of the ordinary, but not cause for great concern</li>
<li>Error: means something didn't happen as expected</li>
<li>Crit: means there are import issues that must be addressed</li>
<li>Alert: means that there are very important issues that require prompt action</li>
<li>Emergency referes to a situation where the system is unusable</li>
</ul></aside>
                </section>

                <section>
                	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">access_log</span></pre> Directive</h3>
                	<ul>
                		<li>Records all attempts to access the server</li>
                		<li>Default log type is <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;"><i>combined</i></span></pre></li>
                	</ul>
                	<pre><code class="linux" data-trim contenteditable>
                			#Example
access_log /var/log/nginx/server3.access.log combined;
                		</code></pre>

                	<aside class="notes">
                		<p>The access log is good for security and auditing all attempted accesses to your server and is specified using the access log directive.
FOr the example: this is the output and what gets written to the access.log using the combined log type.
</p>
<p>To use the access_log directive, specify the file path and log type
</p></aside>
                </section>

                <section>
                	<h3>Logging Best Practices</h3>
                	<p>Keep a separate log files for each server</p>
                	<pre><code class="linux" data-trim contenteditable>
                			server {
    server_name server1.com;
    root /data/server1.com;
    error_log logs/server1.error.log 	info;
}

server {
    server_name server2.com;
    root /data/server2.com;
    error_log logs/server2.error.log 	info;
} 

                		</code></pre>

                	<aside class="notes">
                		<p>Indivudal log files help to reduce size of each log file and makes troubleshooting easier</p>
                	</aside>
                </section>

                <section>
                	<h3>Rotating Logs</h3>
                	<p>Run this shell script in a <i>cron</i> job</p>
                	<pre><code class="linux" data-trim contenteditable>
                		#Get Yesterday's date as YYYY-MM-DD
YESTERDAY=$(date -d 'yesterday' '+%Y-%m-%d')
PID_FILE=/run/nginx.pid
LOG_FILE=/var/log/error.log
OLD_FILE=/var/log/error-$YESTERDAY.log

#Rotate yesterday's log.
mv $LOG_FILE $OLD_FILE

#Tell nginx to open the log file
kill -USR1 $(cat $PID_FILE)
                	</code></pre>
                	<div style="text-align:center;"><small>Documentation: <a href="https://www.nginx.com/resources/wiki/start/topics/examples/logrotation/" target="_blank">Log Rotation</a></small></div>
                	<aside class="notes">
                		<p>Sends kill signal to master process, creates new log file with date appended</p>
                		<p>This script can be used with any log file, including the access log</p>
                		<p>In the past NGINX had a JS file that essentially did the same thing, but since newer versions it's been deprecated. This is the recommended way to roate your log files moving forward</p>
                	</aside>
                </section>

                <section>
                	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">syslog</pre> Protocol</h3>
                	<p>Use this protocol when sending messages to syslog servers such as: <i>splunk</i>, or <i>syslog-ng</i></p>
                	<pre><code class="linux" data-trim contenteditable>
                		error_log syslog:server=192.168.1.1 debug;

access_log syslog:server=unix:/var/log/nginx.sock,nohostname;
access_log syslog:server=[2001:db8::1]:12345,facility=local7,tag=nginx,severity=info combined;
                	</code></pre>
                	<div style="text-align:center;"><small>Documentation: <a href="https://nginx.org/en/docs/syslog.html" target="_blank">Syslog</a></small></div>
                	<aside class="notes">
                		<ul>
<li>server=address: defines the address of the syslog server</li>
<li>facility=string: Sets the syslog message</li>
<li>tag=string: Sets any tags associated with the syslog message, default in this case is 'nginx'</li>
<li>nohostname: disables adding the hostname in the syslog header</li>
</ul>
                	</aside>
                </section>

                <section data-state="lab">
		  <h3>Lab 3: Setup Logging</h3>
		  <ol>
		    <li>Open server1.conf at <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx/conf.d</span></pre> and add an <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">error_log</span></pre> and <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">access_log</span></pre> directive</li>
		    <li>Set the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">error_log</span></pre> to <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">info</span></pre>, and the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">access_log</span></pre> to <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">combined</span></pre></li>
		    <li>Repeat the same steps for server2.conf</li>
		   	<li>Save and Reload NGINX</li>
		    <li>Open your browser and test your http://server:90/</li>
		    <li>Back in your terminal, run a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">tail -f</span></pre> command. What do you see?</li>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
		  		server {
    listen 80;
    root /home/student1/public_html;
    error_log /var/log/nginx/server1.error.log info;
    access_log /var/log/nginx/server1.access.log combined;
		
    location /application1 {
	    proxy_pass http://localhost:90/sampleApp/;
	}
  		
    location /application2 {

	}

    location /images {
	    root /data;
	}
}

server {
    listen 8080;
    root /data/server2;
    error_log /var/log/nginx/server2.error.log info;
    access_log /var/log/nginx/server2.access.log combined;
}
		  	</pre></code>
</aside>

		</section>

<!--Next Section-->
		<section data-background="rgb(20, 149, 62)">
                  <h2>Security</h2>
                 </section>

                 <section>
                  <h3>Module Objectives</h3>
                  <p>This module enables you to:</p>
                  <ul>
                    <li>Configure a HTTPS server</li>
                    <li>Understand how NGINX handles SSL</li>
                    <li>Set limit rates</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>
		<section>
                	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">http_ssl_module</pre></h3>
                	<ul>
                		<li>Provides directives for configuring and managing HTTPS servers</li>
                		<li>Requires <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">openssl</span></pre> Library</li>
                	</ul>
                	<aside class="notes">
                		<p>When compiling from source, it's not built by default so you will have to use the --with parameter using the configure tool</p>
                		<p>If you installed nginx from a binary distribution however, this module should be included</p>
                		<p>The only caveat here is that you must have openssl installed and configured on your machine</p>
                	</aside>
                </section>
        <section>
        	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">ssl</pre> vs. <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">proxy_ssl</pre></h3>
        	<img src="assets/images/sslvsproxyssl.png" style="border:0; background:none; width:100%">
        	<aside class="notes">
<p>ssl: encrypting incoming client connection (SSL Termination)</p>
<p>proxy_ssl: encrypting proxied connections</p>
        	</aside>
        </section>

        <section>
        	<h3>SSL Termination</h3>
        	<p>SSL terminates at NGINX level, NGINX handles handshake overhead to take load off the backends</p> 
        	<pre><code class="linux" data-trim contenteditable>
        		http {
    ssl_session_cache   shared:SSL:10m;
    ssl_session_timeout 10m;

    server {
        listen              443 ssl;
        server_name         www.example.com;
        keepalive_timeout   70;

        ssl_certificate     www.example.com.crt;
        ssl_certificate_key www.example.com.key;
        ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;
        ssl_ciphers         HIGH:!aNULL:!MD5;
        ...
    }
}
        	</code></pre>
        	<div style="text-align:center;"><small>Documentation: <a href="https://www.nginx.com/resources/admin-guide/nginx-ssl-termination/" target="_blank">SSL Termination</a></small></div>
        	<aside class="notes">
<p>SSL operations consume extra CPU resources. The most CPU-intensive operation is the SSL handshake. There are two ways to minimize the number of these operations per client:</p>
<ul>

<li>Enabling keepalive connections to send several requests via one connection</li>
<li>Reusing SSL session parameters to avoid SSL handshakes for parallel and subsequent connections</li>
</ul>

<p>Sessions are stored in the SSL session cache shared between worker processes and configured by the ssl_session_cache directive. One megabyte of cache contains about 4000 sessions.</p> 
<p>The default cache timeout is 5 minutes. This timeout can be increased using the ssl_session_timeout directive.</p> 
<p>This is a sample configuration optimized for a multi-core system with 10 megabyte shared session cache:</p>
        	</aside>
        </section>

        <section>
        	<h3>Configuring an HTTPS Server</h3>
        	<ul>
        		<li>Define <i>ssl</i> on listen port</li>
        		<li>Generate trusted certificate and private key</li>
        		<li>Configure protocols and ciphers</li>
        	</ul>
        	<aside class="notes">
        		<p>So diving a little bit deeper, let's explore how to setup HTTPS based on each directive</p>
        		<p>The first thing you may have noticed in the previous slide was that we were listening on the standard SSL port 443, and also we appeneded the ssl parameter on the listen port</p>
        		<p>Next thing we need to do is define a certificate and private key. As a quick reminder the certs are sent to the clients, whereas the private key is used in the trust store to make sure the server is the legititmate destination</p>
        		<p>Finally we can specifidy the ssl protocols and ciphers, which will indicate which device and browser combo are accpeted by the nginx configurations</p>
        		<p>For example: older browsers, OS's, and platforms are vulnerable to various kinds of attacks, so limiting access to these will imporve website security, however there will be a trade off with alienating a portion of your user base.</p>
        	</aside>
        </section>

        <section>
        	<h3>Certs and Keys</h3>
        	<p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">ssl_certificate</pre> = the public certificate</p>
        	<p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">ssl_certificate_key</pre> = the private key</p>
        	<pre><code class="linux" data-trim contenteditable>
        		server  {
    listen  443 ssl;
    root /data;

    error_log /var/log/nginx/secure_server.error.log

    ssl_certificate /etc/nginx/nginx.crt:
    ssl_certificate_key /etc/nginx/nginx.key;
}

        	</code></pre>
        	<aside class="notes">
        		<p>The server certificate is a public entity. It is sent to every client that connects to the server.</p> 

<p>The private key is a secure entity and should be stored in a file with restricted access, however, it must be readable by nginx’s master process.</p> <p>The private key may alternately be stored in the same file as the certificate:</p>
</aside>
        </section>

        <section>
        	<h3>Protocols and Ciphers</h3>
        	<p>ssl_protocols</p>
        	<pre><code class="linux" data-trim contenteditable>
        		ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
        	</code></pre>
        	<p>ssl_ciphers</p>
        	<pre><code class="linux" data-trim contenteditable>
ssl_ciphers ECDH+AESGCM:ECDH+AES256:ECDH+AES128:DH+3DES:!ADH:!AECDH:!MD5
        	</code></pre>
        	<div style="text-align:center;"><small>Documentation: <a href="http://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_ciphers" target="_blank">SSL Ciphers</a></small></div>
        	<aside class="notes">
<p>Use the ssl_protocols directive to specify which protocols are enabled
ssl_ciphers configures which ciphers to use</p>
<p>Follows the OpenSSL format, and dependingin on which protocols you disable or enable it will provide more or less security. We have detailed explanations on how to get an A+ rating on SSLLabs.com in other courses, but these examples provide a general idea</p>
        	</aside>
        </section>

        <section>
        	<h3>Perferred Ciphers</h3>
        	<p>Configure NGINX to tell client there is a preferred order of available cipher suites
</p>
<p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">ssl_prefer_server_ciphers on;</span></pre></p>
        	<aside class="notes"></aside>
        </section>

        <section>
        	<h3>Dual Stack "RSA" and "ECC"</h3>
       <pre><code class="linux" data-trim contenteditable>
       			server { 
    listen 443 ssl; 
    server_name example.com;

    #RSA cert
    ssl_certificate example.com.rsa.crt;
    ssl_certificate_key example.com.rsa.key;

    #ECC cert
    ssl_certificate example.com.ecdsa.crt;
    ssl_certificate_key example.com.ecdsa.key; 
}
       </code></pre>
        	<aside class="notes">

        		<p>ECC is 3x quicker than equivalent‑strength RSA certificates</p>
<p>To support both RSA and ECC certificates, in the configuration include pair of ssl_certificate and ssl_certificate_key directives for each certificate type.</p>
<p>With NGINX Plus R10, you can publish SSL/TLS services using both RSA and ECC certificates. In our testing, ECC certificates were up to 3x quicker than equivalent‑strength RSA certificates; this translates to more SSL/TLS connections per server and faster SSL/TLS handshakes.</p>
<p>NGINX Plus selects the optimal certificate based on each client’s capabilities, allowing modern clients to use higher‑speed ECC certificates while still supporting legacy RSA‑only clients.
</p>
        	</aside>
        </section>
<section>
        <section>
        	<h3>Popular Use Cases</h3>
        	<p>Combine HTTP & HTTPS</p>
        	<pre><code class="linux" data-trim contenteditable>
        		    server {
    listen 443;
    listen 80;
    server_name example.com;
    root /home/student1/public_html;
}
        	</code></pre>
        	<aside class="notes">
	<p>A server that can accept both HTTP and HTTPS requests
Gives the flexibility of just having one server to handle both requests as opposed to having to define another server
Use multiple listen directives</p>
</aside>
</section>

	
		<section>
		<h3>Popular Use Cases</h3>
        	<p>Force incoming traffic to HTTPS</p>
        	<pre><code class="linux" data-trim contenteditable>
        		#server 1
server {
    listen 80;
    return 301 https://$host$request_uri;
}

#server 2
server {
    listen 443 ssl;
    ssl_certificate /etc/nginx/ssl/server.crt;
    ssl_certificate_key /etc/nginx/ssl/server.key;
}
        	</code></pre>
        	<aside class="notes">

<p>Security best practice is to only serve content over HTTPS.
If a user makes a request over HTTP, we can redirect to HTTPS using a 301 return code
</p>
        	</aside>
        </section>
    </section>

         <section data-state="lab">
		  <h3>Lab 4: Configure HTTPS</h3>
		  <ol>
		    <li>Use openssl to generate a cert and key in <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx:</pre>
<pre><code class="linux" data-trim contenteditable>
	sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout nginx.key -out nginx.crt </code></pre></li>
		    <li>In <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx/conf.d</pre> open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">example_ssl.conf</span></pre></li>
		    <li>Uncomment the example HTTPS server block</li>
		   	<li>Replace your cert and key with the one you generated</li>
		    <li>Save and reload NGINX</li>
		    <li>Test http://server/ index page using https</li>
		    <li>Click-through the warning message, what do you see?</li>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
		  		server {
    listen 443 ssl;
    root /usr/share/nginx/html;

    ssl_certificate /etc/nginx/nginx.crt;
    ssl_certificate_key /etc/nginx/nginx.key;
...
		  	</pre></code>


</aside>
		</section>

<section>
        <h3>Restricting Access</h3>
        <ul>
        	<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">allow</pre> specifies access to a server or location block</li>
<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">deny</span></pre> directive prevents access</li>
</ul>
        <aside class="notes">
        Both directives can be applied at the HTTP context, server or location block
Can specify an IP address, domain name or Unix socket</aside>
    </section>

    <section>
        <h3>Basic HTTP Authentication</h3>
        <p>Requires users to specify a login and password via the browser. Syntax is:</p>
        <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">auth_basic <i>realm</i> | off</span></pre></p>
        <aside class="notes">
        	<ul>
<li>Can be enabled at the HTTP context level, server context or location context</li>

<li>“Off” is used to turn off authentication</li>
<li>Requires a password file to be defined</li>
<li>Password file is specified via the auth_basic_user_file directive</li>
</ul>
        </aside>
    </section>

    <section>
        <h3>Basic Auth Example</h3>
        <pre><code class="linux" data-trim contenteditable>
        	server {
    listen 8080;
    root /home/johnny/public_html;

    auth_basic “restricted server”;
    auth_basic_user_file /etc/nginx/htpasswd;

    location /public_area {
        auth_basic off;
    }
}

        </code></pre>
        <aside class="notes"></aside>
    </section>

    <section>
        <h3>Password File</h3>
        <ul>
        	<li><pre style="display:inline; color:rgb(255,255,255);"><span style="font-size: 30px;">crypt()</span></pre></li>
        	<li><pre style="display:inline; color:rgb(255,255,255);"><span style="font-size: 30px;">openssl passwd</span></pre></li>
        </ul>
        <pre><code class="linux" data-trim contenteditable>
        	name1:password1
name2:password2
#comments
        </code></pre>
        <aside class="notes">
Usernames and passwords are stored in a file
Passwords must be encrypted in one of the following ways:
crypt() function of the “htpasswd” utility from Apache
openssl passwd command

        </aside>
    </section>

    <section>
        <h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">auth_request</span></pre> Module</h3>
         <pre><code class="linux" data-trim contenteditable>
         	server {
    listen 443 ssl;
    root /usr/share/nginx/html;
...
    location /private {
        auth_request /auth;
        auth_request_set  $user $upstream_http_x_user;
        proxy_set_header x-user $user; 
        proxy_pass http://backend_server;
    }
}
         </code></pre>
        <aside class="notes">
<ul>
	<li>Implements auth based on result of subrequest rather than validating user and pass via browser.</li>
<li>auth_request uri | off: Enables auth and sets URI where requests are sent </li>
<li>auth_request_set: Sets the request variable  value after the authorization request completes</li>
</ul>
<p>Auth_request_set: The value may contain variables from the authorization request, such as $upstream_http_*.
</p>
        </aside>
    </section>

<section data-state="lab">
		  <h3>Lab 5: Setup Basic Authentication</h3>
		  <ol>
		    <li>Open the password file called “htpasswd” inside <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx</span></pre></li>
		    <li>Delete the password for the admin entry</li>
		    <li>Close and save the file. Back in the terminal, run <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">openssl passwd</span></pre></li>
		   	<li>Specify any user and password. Copy the encrypted output to your clipboard and
		    paste into htpasswd</li> 
		    <li>Open server1.conf and enable authentication on the server level</li>
		    <li>Save and reload NGINX. Open a browser and hit http://server</li>
			<li>Login with your username and password you specified</li>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
		  		server {
    listen 80;
    root /home/student1/public_html;

    error_log /var/log/nginx/server1.error.log info;
    access_log /var/log/nginx/server1.access.log combined;

    auth_basic "protected";
    auth_basic_user_file /etc/nginx/htpasswd;
...
		  	</pre></code>
</aside>
		</section>

		<section>
			<section>
        <h3>Setup Limit Rates</h3>
         <p>Limitations based on:</p>
         <ul>
         	<li class="fragment" data-fragment-index="0"> Number of Connections</li>
         	<li class="fragment" data-fragment-index="1">Number of Requests</li>
         	<li class="fragment" data-fragment-index="2">Download Speeds</li>
         </ul>
        <aside class="notes">
<ul>
	<li>The number of connections can be limited based on a key value (usually per IP address or per server)</li>
<li>The number of requests that can be processed per second or per minute
</li>
<li>Throttle Download Speeds</li>
</ul>
<p>Auth_request_set: The value may contain variables from the authorization request, such as $upstream_http_*.
</p>
        </aside>
    </section>

    <section>
        <h3>Limiting Connections</h3>
        <ul>
        	<li>Define a Shared Memory Zone</li>
        	<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">limit_conn_zone</span></pre> defines: zone, size, name, and key</li>
        	<li>Syntax is: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">limit_conn_zone $variable zone=name:size;</span></pre></li>
        </ul>

        <aside class="notes">
<p>Here, a client IP address serves as a key. Note that instead of $remote_addr, the $binary_remote_addr variable is used here. The $remote_addr variable’s size can vary from 7 to 15 bytes.</p>
<p>The stored state occupies either 32 or 64 bytes of memory on 32-bit platforms and always 64 bytes on 64-bit platforms. The$binary_remote_addr variable’s size is always 4 bytes. The stored state always occupies 32 bytes on 32-bit platforms and 64 bytes on 64-bit platforms. </p>
<p>One megabyte zone can keep about 32 thousand 32-byte states or about 16 thousand 64-byte states. If the zone storage is exhausted, the server will return the 503 (Service Temporarily Unavailable) error to all further requests.</p>


<p>Directive must be defined in the HTTP context</p>
<p>Variable can be:</p>
<ul>
<li>$binary_remote_addr</li>
<li>$server_name</li>
</ul>
        </aside>

    </section>
    <section>
    	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">limit_conn</pre></h3>
    	<p>Specify shared memory zone in desired context</p>
    	<p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">limit_conn zone number_of_connections</span></pre>;
<pre><code class="linux" data-trim contenteditable>
		http {
    limit_conn_zone $binary_remote_addr zone=ip:10m;

    server {
	…
        location /downloads {
	        limit_conn ip 5; 
    }

		  	</pre></code>
    	<aside class="notes">
    		<p>Use limit_conn directive on the http, server or location context to apply the limitation</p>
    	</aside>
	</section>

	<section>
        <h3>Limiting Request Rate</h3>
        
        <p>Set request rate, name, key, and duration in Shared Memory Zone</p>
        <p>Example:<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">limit_req_zone $server_name zone=one:10m rate=1r/s</span></pre></p>

        <aside class="notes">
<p>Use limit_req_zone directive on the http context to set shared memory zone</p>
<p>Set the rate in either requests per second or request per minute</p>
<p>Like in this example we're setting a request rate zone based on the predefined $server_name variable as the key, the zone name is one with a size of ten megabytes, and the rate is 1 request per second</p>
<p> To use this shared memory zone we need to specify the limit_req directive in the server or location context (details on next slide)</p>
        </aside>

    </section>

	<section>
    	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">limit_req</span></pre></h3>
    	<p>Syntax:<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">limit_req zone='name' [burst=n.o | nodelay];</span></pre></p>
</p>
<pre><code class="linux" data-trim contenteditable>
		http {
	limit_req_zone $server_name zone=ten:10m rate=10r/s
	…
	server {
		…
		
		location /data {
			limit_req zone=ten burst=15;
		}
	} 
}
		  	</pre></code>
    	<aside class="notes">
    		<p>Burst parameter specifies the maximum number of requests that can be queued for processing</p>
			<p>If the number is exceeded, NGINX responds with 503 error. Specifying “nodelay” means requests cannot be queued</p>
			<p>In this example we're defining a request rate zone with the $server_name variable as the key again. Then the name and size of the zone "zone=ten:10m," and finally the request rate which is 10 requests per second.</p>
			<p>Now when we apply the limitation we also use the burst parameter, this value should never be less than the request rate, this value of 15 means that 15 additional requests will be placed in a processing queue, and if any more requests reach the server the server will respond with a 503 error.</p>
    	</aside>
	</section>
<section>
        <h3>Limiting Download Rate</h3>
        
        <p>Syntax:<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">limit_rate <i>speed</i></pre></p>
        	<pre><code class="linux" data-trim contenteditable>
	location /media {
    limit_conn ipzone 5;
    limit_rate 50k;
}
		  	</pre></code>
        <aside class="notes">
        	<p>Much like <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">limit_conn</pre> and <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">limit_req</span></pre></p>
<p>Apply limit_rate directive in the HTTP, server or location contexts</p>
<p>Syntax:
limit_rate speed</p>
<p>Speed is defined in bytes per second</p>
<p>Rate limit is applied to each connection</p>
<p>Can be used in conjunction with limiting connections</p>
        </aside>
    </section>

    <section>
    	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">limit_rate_after</span></pre></h3>
    	<p>Throttle download speeds after client builds a buffer</p>
<pre><code class="linux" data-trim contenteditable>
		location /videos {
    limit_rate_after 500k;
    limit_rate 50k;
}
		  	</pre></code>
    	<aside class="notes">
<p>Download speeds can be capped after a certain amount has been transmitted to a client</p>
<p>Use limit_rate_after directive and specify the amount after which speeds will be limited</p>
<p>Useful for video streaming delivery</p>
<p>Allow client to use max download speeds to build a buffer</p>
<p>Then limit download based on bitrate of the video file to allow smooth playback without excessive use of bandwidth</p>
    	</aside>
    </section>

</section>

<!--Next Section-->
		<section data-background="rgb(20, 149, 62)">
                  <h2>Variables</h2>
                 </section>

<section>
          <h3>Module Objectives</h3>
             <p>This module enables you to:</p>
                <ul>
                <li>Gain knowledge of NGINX's predefined variables</li>
                <li>Understand Variable Scope with regards to NGINX</li>
                <li>Define your own custom variables</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>

                <section>
                  <h3>Core Module Variables</h3>
                   <table style ="width:100%; color:rgb(255,255,255); display:inline;" >
        <tr>
          <th>Variable</th>
          <th>Value</th>
        </tr>
        <tr class="fragment" data-fragment-index="0">
          <td><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$host</span></pre></td>
          <td>Host name from request line</td>
        </tr>
        <tr class="fragment" data-fragment-index="1">
		  <td><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$request_uri</span></pre></td>
          <td>The full URI, including arguments</td>
        </tr>
         <tr class="fragment" data-fragment-index="2">
		  <td><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$uri</span></pre></td>
          <td>Normalized URI (no arguments)</td>
        </tr>
        <tr class="fragment" data-fragment-index="3">
		  <td><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$scheme</span></pre></td>
          <td>Request scheme (HTTP or HTTPS)</td>
        </tr>

        <tr class="fragment" data-fragment-index="4">
		  <td><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$request_method</span></pre></td>
          <td>GET, POST, PUT etc.</td>
        </tr>

        <tr class="fragment" data-fragment-index="5">
		  <td><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$request_filename</span></pre></td>
          <td>Absolute file path for current request</td>
        </tr>

        <tr class="fragment" data-fragment-index="6">
		  <td><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$remote_addr</span></pre></td>
          <td>IP address of client</td>
        </tr>
      </table>
                  <aside class="notes"></aside>
                </section>
<section>
          <h3>Variable Example</h3>
             <p>Given URL: http://localhost:8080/test?arg=1</p>
                <ul>
                <li class="fragment" data-fragment-index="0"><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$host</span></pre> = localhost</li>
                <li class="fragment" data-fragment-index="1"><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$request_uri</span></pre> = /test?arg=1</li>
                <li class="fragment" data-fragment-index="2"><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$uri</span></pre> = /test</li>
                <li class="fragment" data-fragment-index="3"><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$scheme</span></pre> = http://</li>
                <li class="fragment" data-fragment-index="4"><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$args</span></pre> = ?arg=1</li>
		  </ul>
		  <p>Usage Example:</p>
		  <pre><code class="linux" data-trim contenteditable>
	server {
    listen 80;
    return 301 https://$host$request_uri;
}
		  	</pre></code>
                  <aside class="notes"></aside>
                </section>

                <section>
          <h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">set</pre> Directive</h3>
             <p>Syntax:<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">set $variable_name <i>value</i>;</span></pre></p>
              <pre><code class="linux" data-trim contenteditable>
	set $foo hello;
set $bar “hello world”;
set $combo $foo
		  	</pre></code>
                  <aside class="notes"></aside>
                </section>

                <section>
          <h3>Declaration and Scope</h3>
             <p></p>
              <pre><code class="linux" data-trim contenteditable>
              	server {
    listen 8080;

        location /test1 {
            return 200 = "foo $foo \name example = $example \n";
        }

        location /test2 {
            set $foo hello;
            return 200 = "foo = $foo \n";
        }
}

server {
    listen 8081;

    set $example 42;

    location / {
        return 200 "foo = $foo \n";
    }
}
		  	</pre></code>
                  <aside class="notes">
<p>Variables must be declared when NGINX loads the configuration file</p>
<p>Values are assigned at run time</p>
<p>Variables can be accessed across the entire configuration</p>
<p>Each request runs its own variable container</p>
<p>So given this example, which requests will actually server or print the variable name given our requests are:</p>
<ul>
	<li>http://server:8080/test1</li>
	<li>http://serverL8080/test2</li>
	<li>http://server:8081/</li>
</ul>
<p>Answer: only test2 will print "hello" because our variable is declared correctly for that request, others are either set in the incoorect position or not even declared in the same server. You can think of variable declaration in NGINX a lot like Java method invocation for those of you with a programming background</p>
                  </aside>
                </section>

                <section>
          <h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">map</pre> Directive</h3>
             <p>Creates a mapping relationship between two variables</p>
             <p>Syntax:<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">map $var1 $var2 {<i>value</i> <i>value</i>}</span></pre></p>
              <pre><code class="linux" data-trim contenteditable>
	map $uri     $path {
    /test1   /path1
    /test2   /path2
    /test3   /path3
}

server {
	listen 80;

	location /test1 {
        return 200 "$path \n";
    }
}

		  	</pre></code>
                  <aside class="notes">
<p>map directive defines a mapping relationship between two variables</p>
<p>The value of $var2 depends on the value of $var1</p>
<p>$var1 can be a pre-defined variable or a custom defined variable</p>
<p>Mapped variables are evaluated only when used. There creating large numbers of maps will not add extra costs to processing a request</p>
                  </aside>
                </section>

<section>
	<h3>Default Value</h3>
	<pre><code class="linux" data-trim contenteditable>
	map $arg $value {
    default 1;
    test1 2;
}
	</pre></code>
	<aside class="notes">
<p>map directives contains a special “default” parameter, which allows us to set a default value</p>
<p>Example</p>
<pre><code class="linux" data-trim contenteditable>
	$value equals “2” if $arg equals “test1”
</pre></code>
<p>Otherwise $value equals “1” </p>
	</aside>
</section>

<section>
	<h3>Regex in Maps</h3>
	<pre><code class="linux" data-trim contenteditable>
map $uri $path {
    ~*/test/.*\.php$ /path4;
    /example /examplePath;
}
	</pre></code>
	<aside class="notes">
<p>A regular expression can contain named and positional captures that can later be used in other directives along with the resulting variable.</p>
 <p> - what does this mean?</p>

<p>Regex in maps cannot use capture groups</p>
<p>Value of the map variable can be determined by regular expression</p>
<p>Regex starts with ~ for case sensitive matching</p>
<p>~* for case insensitive matching</p>


	</aside>
</section>

<section data-state="lab">
		  <h3>Lab 6: Map Example</h3>
		  <ol>
		    <li>Create a map for a variable called <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$is_redirect</span></pre> that depends on the predefined <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$uri</span></pre> variable.</li> 
			<li>Set variable relationships as follows:
				<ul>
					<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">default  0;</span></pre></li>
					<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/test1    1;</span></pre></li>
					<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/test2    2;</span></pre></li>
					<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/test3    3;</span></pre></li>
				</ul>
			</li>
			<li>Create a regex for /test:
				<pre><code class="linux" data-trim contenteditable>
					server {
	....
	location ~* /test(\d+)$ {
        return 200 "variable = $is_redirect \n";
    }
}
				</code></pre></li>
		    
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
    map $uri $is_redirect {
    default    0;
    /test1    1;
    /test2    2;
    /test3    3;
}

server {
	....
	location ~* /test(\d+)$ {
        return 200 "variable = $is_redirect \n";
    }
}

#curl request
curl http://localhost/test1, /test2, /test3, /test4, /test4241234
		  	</pre></code>
</aside>
		</section>

		<!--Next Section-->
		<section data-background="rgb(20, 149, 62)">
                  <h2>Routing Connections</h2>
        </section>

        <section>
          <h3>Module Objectives</h3>
             <p>This module enables you to:</p>
                <ul>
                <li>Use specific directives in NGINX to reroute traffic</li>
                <li>Define URL Rewrites</li>
                <li>Understand Rewrite Request processing</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>

                <section>
          <h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">alias</span></pre> Directive</h3>
             <p>Allows you to specify a replacement path</p>
             <p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">alias <i>path</i>;</span></pre>
                <pre><code class="linux" data-trim contenteditable>
                	server {
    root /home/public_html;

    location /test {
	    alias /data/app1;
	}
}
                </pre></code>
		 
                  <aside class="notes">
<p>The alias directive defines a replacement path for a specified location block</p>
<p>Path can be a variable, except for $document_root and $realpath_root</p>
<p>In this example, Requests to <i>server</i> will load the index.html file in /home/public_html
</p>
<p>Requests to <i>server</i>/test/app.html will load app.html file from /data/app1
</p>
                  </aside>
                </section>
<section>
<section data-state="lab">
		  <h3>Lab 7: Alias Replacement</h3>
		  <ol>
		    <li>Change directory to <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx/conf.d</span></pre> and open<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server1.conf</span></pre>.</li> 
			<li>In <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/application2</span></pre> prefix, specify a replacement path of <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/data/test</span></pre> using the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">alias</span></pre> directive.</li>
		    <li>Save the file and reload Nginx. Test against <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">http://server/application2/logo.png</span></pre> What do you observe? Try the other URIs</li>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
        location /application2 {
    alias /data/test;
}

location /images {
    root /data;
}
		  	</pre></code>
</aside>
		</section>

		<section>
			<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">alias</span></pre> with Regex</h3>
			<pre><code class="linux" data-trim contenteditable>
				location ~ ^/pictures/(.+\.(?:gif|jpe?g|png))$ {
    alias /data/images/$1;
    }
			</pre></code>
			<aside class="notes">
<p>To get regex to work with alias we need two things:</p>
<ul>
	<li>A regular experssion with at least one catprue group</li>
	<li>A reference to that regex in our alias path</li>
</ul>
<p>So in this example we have a location regex that is looking for a uri of pictures, followed by any character preceding a dot, folowed by the possible extension names.</p>
<p>The $ sign indicates the end of the expression, and the $1, represents the capture group.</p>
<p>So in this case $1 means the ENTIRE capture group, if it was $2, alias would only concern itself with the second group of paranthesis</p>
			</aside>
		</section>

		<section data-state="lab">
		  <h3>Lab 7.5: Regex Alias</h3>
		  <ol>
		    <li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server1.conf</span></pre> and edit the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/images</span></pre> prefix to be a case insensitive regex, with a URI match of <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/pictures.</span></pre></li> 
			<li>In the regular expression, ensure that the capture group includes 1 or more occurences of any character followed by a "." and ending in either <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">gif, jpeg, jpg,</span></pre> or, <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">png</span></pre></li> 
			<li>Inside the location block, define the replacement path as: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/data/images/$1</span></pre></li>
		    <li>Save the file and reload Nginx. Test against <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">http://server/pictures/logo.png</span></pre> What do you observe?</li>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
        location /application2 {
    alias /data/test;
}

location ~ ^/pictures/(.+\.(gif|jpe?g|png))$ {
    alias /data/images/$1;
}
		  	</pre></code>
</aside>
		</section>
	</section>

 <section>
          <h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">return</span></pre> Directive</h3>
             <p>Return a HTTP response code and URL to the client</p>
             <p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">return <i>code</i> <i>url</i>;</span></pre> or <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">return <i>url</i>;</span></pre></p>
                <pre><code class="linux" data-trim contenteditable>
                	server {
    listen 8080;
    root /home/public_html;

    location /test {
	    return http://localhost:8081$uri;
	}

server {
    listen 8081;
    root /data/app1;
    autoindex on;
    }
}
                </pre></code>
		 
                  <aside class="notes">
<p>The return directive allows you to specify a HTTP response code and URL</p>
<p>To redirect, use HTTP response codes 301, 302, 303 or 307
</p>
<p>Response code is optional, URL can contain variables</p>
<p>Request to <i>server</i>:8080/test/test.html</p>
<p>$uri = /test/test.html</p>
<p>Re-directed to <i>server</i>:8081/test/test.html</p>

                  </aside>
                </section>

                <section>
          <h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">rewrite</span></pre> Directive</h3>
             <p>Regex pattern matched against URI, replacement string rewrites the URI.</p>
             <p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">rewrite <i>regex</i> <i>replacement</i> [flag]</span></pre></p>
                <pre><code class="linux" data-trim contenteditable>
                	server {
    listen 8080;
    root /home/public_html;
    rewrite ^/shop/products/(\d+) /myshop/products/product$1.html;
}
                </pre></code>
		 
                  <aside class="notes">
<p>The rewrite directive allows you to specify a regex pattern, which is matched against a request URI. 
If the URI matches the pattern, it is then changed according to the specified replacement string</p>

<p>It can be used in the server and location context</p>

<p>In this example, Regex pattern looks for URIs beginning with /shop/products/ followed by one or more occurrences of any number</p>
<p>Example: /shop/products/1</p>
<p>Replacement string changes the URI into /myshop/products/product1.html</p>
<p>$1 is the variable that stores the value of the capture group (\d+)</p>
                  </aside>
                </section>

                <section>
<section data-state="lab">
		  <h3>Lab 8.1: Setting Up Rewrite Data</h3>
		  <ol>
		    <li>Inside your <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">public_html</span></pre> folder, ensure that there are the following directories and files: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/shop/products/product1.html product2.html product3.html</span></pre></li> 
			<li>Inside <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">product1.html</span></pre> edit the paragraph tag by removing <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">8080</span></pre> and replacing <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">&#60;server&#62;</span></pre> with your ec2 url</li> 
			<pre><code class="html" data-trim contenteditable>
				&#60;p&#62;
&#60;img src="&#60;server&#62;/media/pics/logo.png"/&#62;
&#60;/p&#62;

			</pre></code>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
		  	</pre></code>
</aside>
		</section>

<section data-state="lab">
		  <h3>Lab 8.2: Rewrite URLs</h3>
		  <ol>
		    <li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server1.conf</span></pre> in <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx/conf.d</span></pre></li> 
			<li>Inside the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre> context, define a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">rewrite</span></pre> regex:
<pre><code class="html" data-trim contenteditable>
	^/shop/greatproducts/(\d+)$ 
</code></pre>
				and a replacement string:
<pre><code class="html" data-trim contenteditable>
	/shop/products/product$1.html
</code></pre></li>
<li>Save your file and reload nginx</li>
<li>Open your browser and test against:
<ul>
<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">&#60;server&#62;/shop/greatproducts/2</span></pre></li> 
<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">&#60;server&#62;/shop/greatproducts/3</span></pre></li>
<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">&#60;server&#62;/shop/greatproducts/1</span></pre></li>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="html" data-trim contenteditable>
rewrite ^/shop/greatproducts/(\d+)$ /shop/products/product1.html;
       
}
</pre></code>
</aside>
		</section>

<section data-state="lab">
		  <h3>Lab 8.3: Rewrite URLs (Continued)</h3>
		  <ol>
		    <li>Now try <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">&#60;server&#62;/shop/greatpoducts/1</span></pre></li>
		    <li>What do you notice about the image?</li>
		    <li>Add another <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">rewrite</span></pre> at the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre> level with the following regex:
		    	<pre><code class="html" data-trim contenteditable>
	^/media/pics/(.+\.(gif|jpe?g|png))$
</code></pre>
			and replacement string:
			<pre><code class="html" data-trim contenteditable>
	/images/$1
</code></pre>
		    </li> 
			<li>Save and reload NGINX</li>
			<li>Re-test <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/shop/greatproducts/1</span></pre></li>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
        rewrite ^/media/pics/(.+\.(gif|jpe?g|png))$ /images/$1;

   
		  	</pre></code>
</aside>
		</section>
	</section>

<section>
	<h3>Rewrite Process Cycle</h3>
	<p>Highlights:</p>
	<ul>
		<li>Executed sequentially</li>
		<li>Executed upon server selection</li>
		<li>All rewrites in higher context are executed first</li>
		<li>Flags will stop further processing</li>
	</ul>
	<aside class="notes">
<p>Rewrite directives are executed sequentially by order of appearance in the configuration file</p>
<p>Rewrite directives on the server level are executed as soon as the server has been selected for processing</p>
<p>Once all rewrite directives have been executed a new location will be selected to process the rewritten URI</p>
<p>The location block can contain additional rewrite directives, and flags will stop processing at a given level</p>

	</aside>
</section>

	<section>
          <h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">rewrite flags</span></pre></h3>
             <p>Prevents further rewrite processing</p>
             <ul>
             	<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">last</span></pre></li>
             	<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">break</span></pre></li>
             	<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">redirect</span></pre></li>
             	<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">permanent</span></pre></li>
             </ul>
		 
                  <aside class="notes">
<p>The last flag stops the processing of rewrite directives in the current server or location and searches for a new location block based on the rewritten URI
Rewrite directives that are present in the new location block will be executed</p>
<p>The break flag stops the processing of all rewrite directives on the current level (server or location) and also stops the search for a new location
Typically used for rewrite directives that are inside a location block</p>
<p></p>
<p>Redirect flag returns a temporary redirect with the HTTP 302 code.</p> 
Permanent flag returns a permanent redirect with the HTTP 301 code.</p>
<p>Both flags will stop further processing of rewrite directives on the current configuration level.
The redirected URL is formed based on the server name and port number of the request and the URI specified by the rewrite directive</p>
                  </aside>
                </section>

<section>
<section data-state="lab">
		  <h3>Lab 9.1: Rewrite Flags</h3>
		  <ol>
		    <li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server1.conf</span></pre> and define a new location block with the prefix <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/shop</span></pre></li>
		    <li>Cut and paste the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">rewrite</span></pre> regarding <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/greatproducts</span></pre>, and paste it into the new <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location</span></pre></li>
		    <li>Add a new <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">rewrite</span></pre> with regex:
		    	<pre><code class="html" data-trim contenteditable>
	 ^/shop/.+/(\d+)$
</code></pre>
			and replacement string:
			<pre><code class="html" data-trim contenteditable>
	/shop/services/service$1.html
</code></pre>
		    </li> 
		    <li>Add a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">return</span></pre> directive with code <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">403</span></pre></li>
			<li>Save and reload NGINX. Re-test <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/shop/greatproducts/1</span></pre></li>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
        rewrite ^/media/pics/(.+\.(gif|jpe?g|png))$ /images/$1;

    location /shop {
        rewrite ^/shop/greatproducts/(\d+)$ /shop/products/product1.html;
        rewrite ^/shop/.+/(\d+)$ /shop/services/service$1.html;
        return 403;
}
		  	</pre></code>
</aside>
		</section>

		<section data-state="lab">
		  <h3>Lab 9.2: Rewrite Flags (Continued)</h3>
		  <ol>
		    <li>Re-open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server1.conf</span></pre> and place <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">break</span></pre> flags after every <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">rewrite</span></pre> in the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location</span></pre> context</li>
			<li>Save and reload NGINX</li>
			<li>Re-test <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/shop/greatproducts/1</span></pre></li>
		  </ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
        rewrite ^/media/pics/(.+\.(gif|jpe?g|png))$ /images/$1;

    location /shop {
        rewrite ^/shop/greatproducts/(\d+)$ /shop/products/product1.html break;
        rewrite ^/shop/.+/(\d+)$ /shop/services/service$1.html break;
        return 403;
}
		  	</pre></code>
</aside>
		</section>
	</section>

 <!--Next Section-->
		<section data-background="rgb(20, 149, 62)">
                  <h2>End of Part One: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">Thank You!</span></pre></h2>
                 </section>

 <!--END OF DAY ONE!!!!!!!!!!!-->

<section>
                <h3>Agenda: Part Two</h3>

                <div style="text-align:left;">
                    <img src="assets/images/NGINXCoreAgenda2.png" style="border:0;background:none; left:0; top:0;">
                </div>
		
		<aside class="notes">
		<p>So for this first day we're going to cover load balancing, then we will monitor our upstream using the status handler, then we will cover caching, then we will cover basic compression, and finally we will explore using the dynamic config api.</p>

		</aside>
              </section>
 <section data-background="rgb(20, 149, 62)">
                  <h2>Load Balancing</h2>
                 </section>

<section>
          <h3>Module Objectives</h3>
             <p>This module enables you to:</p>
                <ul>
                <li>Setup basic load balancer</li>
                <li>Identify load balancing methods</li>
                <li>Enable session persistence</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>


                <section>
          <h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">ngx_http_upstream_module</span></pre></h3>
             <p>Key Take-Aways:</p>
                <ul>
                <li>Defines a group of servers</li>
                <li>Leverages <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_pass</span></pre> directive</li>
                <li>Server definition can be:
                	<ul>
                		<li>Unix socket</li>
                		<li>DNS</li>
                		<li>IP:Port</li>
                	</ul>
                	</li>
		  </ul>
                  <aside class="notes">
<p>Defines a group of servers that can be referenced by a proxy_pass directive</p>
<p>Servers can be defined by their IP address, domain name or Unix socket</p>
<p>Servers can be defined to listen on different ports</p>
<p>Used to set up a load balancing configuration</p>
                  </aside>
                </section>

                <section>
          <h3>Load Balancing</h3>
          <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_pass</span></pre> forwards request to <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream</span></pre> link</p>
          <pre><code class="linux" data-trim contenteditable>
          	upstream myServers {
       server training.example.com;
       server training.example1.com:8080;
       server 192.168.245.27;
          }
          </code></pre>
                  <aside class="notes">
<p>DeUse an upstream block to specify the list of servers that can handle a request</p>
<p>Defined in the http context</p>
<p>Uses the proxy_pass directive to forward requests to your upstream link</p>
<p>NGINX will select an appropriate server from your upstream block by using a weighted round-robin algorithm (default method)</p>
                  </aside>
                </section>

    <section>
          <h3>Specifying Server Priorities</h3>
          <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">weight</span></pre> indicates <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre> priority</p>
          <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">max_fails</pre></code> indicates server-level failures</p>
          <p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">fail_timeout</pre></code>indicates timeout and duration of downtime</p>
          <pre><code class="linux" data-trim contenteditable>
          	upstream myServers {
       server backend.server1 weight=5 max_fails=10 fail_timeout=90s;
       server backend.server2 weight=3 max_fails=4 fail_timeout=60s;
       server backend.server3 weight=4 max_fails=2 fail_timeout=30s;
          }
          </code></pre>
                  <aside class="notes">
<p>Use the weight parameter to indicate a higher or lower weighting for a particular server</p>
<p>max_fails parameter to specify how many failures before a server is marked as unavailable</p>
<p>fail_timeout parameter specifies how long a server is unavailable.</p>
                  </aside>
                </section>

<section>
<section data-state="lab">
		  <h3>Lab 10.1: Setup "Backends"</h3>
		  <ol>
		    <li>In the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx/conf.d</span></pre> , create a new .conf called <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">backends.conf</span></pre> and define a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre> context with the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">root</span></pre> directive pointing to <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/data/backend1</span></pre>. The server should listen on <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">8081</span></pre></li>
			<li>Repeat steps 1 and 2 for the remaning servers. Servers should listen on <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">8082</span></pre> and <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">8083</span></pre> respectively, and the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">root</span></pre> directories are <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/data/backend2</span></pre> and <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/data/backend3</span></pre></li>
		</ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
        server {
	listen 8081;
	server_name server.backend1;
	root /data/backend1;
}

server {
	listen 8082;
	server_name server.backend2;
	root/data/backend2;
}

server {
	listen 8083;
	server_name server.backend3;
	root /data/backend3;
}

		  	</pre></code>
</aside>
		</section>

<section data-state="lab">
		  <h3>Lab 10.2: Configure Load Balancing</h3>
		  <ol>
		    <li>Create a file called <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">myServers.conf</span></pre> and define an <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream</span></pre> with three backend servers using <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">127.0.0.1:&#60;port&#62;</span></pre></li>
		    <li>Create a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre> context that listens on <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">8080</span></pre></li>
		    <li>Set the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">root</span></pre> directive to your <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">public_html</span></pre> directory.</li>
		    <li>Define an <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">error_log</span></pre> with a level of <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">info</span></pre> and an <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">access_log</span></pre> with a level of <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">combined</span></pre></li>
			<li>Create a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location</span></pre> context that matches all requests</li>
			<li>Add a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_pass</span></pre> to forward all request to the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream</span></pre></li>
		</ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
       upstream myServers {
    server localhost:8081;
    server localhost:8082;
    server localhost:8083;
}

server {
    listen 8080;
    root /home/student1/public_html;
    error_log   /var/log/nginx/upstream.error.log info;
    access_log  /var/log/nginx/upstream.access.log combined;


    location / {
        proxy_pass http://myServers;
    }
}
		  	</pre></code>
</aside>
		</section>
	</section>

	<section>
          <h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">ngx_stream_core_module</span></pre></h3>
             <p>Key Take-Aways:</p>
                <ul>
                <li>Used for TCP/UDP Load Balancing</li>
                <li>Also leverages <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_pass</span></pre> directive</li>
                <li>Similar syntax with <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">ngx_http_upstream</span></pre> module</li>
                <li>Version compatibility:
                	<ul>
                		<li>TCP: r5 or greater</li>
                		<li>UDP: r9 or greater</li>
                	</ul>
                	</li>
                	<li>Exists in <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">main</span</pre> context</li>
		  </ul>
                  <aside class="notes">
<p>Defines a group of servers that can be referenced by a proxy_pass directive</p>
<p>Servers can be defined by their IP address, domain name or Unix socket</p>
<p>Servers can be defined to listen on different ports</p>
<p>Used to set up a load balancing configuration</p>
                  </aside>
                </section>
<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">stream</span></pre> Use Cases</h3>
	<ul>
		<li><strong>TCP:</strong> mSQL, LDAP, RTMP</li>
		<li><strong>UDP:</strong> DNS, Syslog, RADIUS</li>
	</ul>
	<aside class="notes"></aside>
</section>

<section>
	<h3>mySQL Example</h3>
	<p>Load Balancings across three SQL servers</p>
	<pre><code class="linux" data-trim contenteditable>
stream { 
    server { 
	    listen 3306; 
	    proxy_pass db;
    } 

    upstream db { 
	    server db1:3306; 
	    server db2:3306; 
	    server db3:3306; 
    }
}
	</code></pre>
	<aside class="notes">TCP load balancing</aside>
</section>

<section>
	<h3>DNS Example</h3>
	<p>Load balances UDP traffic across two DNS servers</p>
<pre><code class="linux" data-trim contenteditable>
stream { 
    upstream dns_upstreams { 
	    server 192.168.136.130:53;
	    server 192.168.136.131:53; 
    }

    server { 
	    listen 53 udp; 
	    proxy_pass dns_upstreams; 
	    proxy_timeout 1s; 
	    proxy_responses 1; 
	    error_log logs/dns.log; 
    } 
}

	
	</code></pre>
	<aside class="notes">UDP load balancing</aside>
</section>

<section>
	<h3>Load Balancing Methods</h3>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">least_conn</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">least_time</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">hash</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">ip_hash</span></pre></li>
	</ul>
	<aside class="notes">
<ul>
	<li><strong>least_conn</strong>method will send the request to the server with the least amount of connections.</li>
	<li><strong>least_time</strong>method will select the server with the lowest average response time and least amount of active connections</li>
	<li><strong>hash</strong>method will select a server based on a hashing key</li>
<li><strong>ip_hash</strong>method will choose server based on clients IP address </li>
</ul>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">least_conn</span></pre> Directive</h3>
	<pre><code class="linux" data-trim contenteditable>
    upstream backendServers {
	least_conn;

	server backend1.com;
	server backend2.com;
	server backend3.com;
}
	</code></pre>
	<aside class="notes">
<p>To use this method, add the least_conn directive into the upstream block</p>
<p>Less need for weighting and can control load more fairly in a situation when some of the requests take longer to complete.</p>
<p>If there are multiple servers with the same number of connections, the weighted round robin method will be applied on those servers</p>

<p>If we specify a weight, say eg. Server 1 weight 1 and server 2 weight 2, nginx will say that server 2 can handle twice the amount of connections to server 1.</p>

<p>So if server 1 has 5 connections and server 2 has 8, nginx will say that server 2 has the least connections, because it should be having 2x connections as server 1</p>

<p>This is weighted least connections</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">least_time</span></pre> Directive</h3>
	<pre><code class="linux" data-trim contenteditable>
		upstream myServers {
	least_time header;

	server backend1.com;
	server backend2.com;
	server backend3.com;
}
	</code></pre>
	<aside class="notes">
<p>Uses of combination of connections and time to receive header or response— a calculate value</p>
<p>Syntax: least_time header | last_byte;</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">hash</span></pre> Directive</h3>
	<pre><code class="linux" data-trim contenteditable>
upstream myServers {
	hash $request_uri;

	server backend1.com;
	server backend2.com;
	server backend3.com;
}

	</code></pre>
	<aside class="notes">
<ul>
	<li>Maps clients to servers using a specified hash key</li>
	<li>Key can be text or based on any variable.</li>
	<li>Keys are re-mapped if servers are added or removed from the upstream group</li>
</ul>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">ip_hash</span></pre> Directive</h3>
	<p>Uses first three octets for IPv4, or entire IPv6 address</p>
	<pre><code class="linux" data-trim contenteditable>
		upstream myapp1 {
    ip_hash;
    server srv1.example.com;
    server srv2.example.com;
    server srv3.example.com;
}
	</code></pre>
	<aside class="notes">
<p>ip_hash uses the first three octets of an IPv4 address or the entire IPv6 address to determine the hash value</p>
<p>Divides the whole range of IP addresses by number of servers available</p>
<p>Guarantees that request from the same client will be sent to the same server</p>
<p>If the server is not available, another server will be selected</p>
<p>If a server needs to be taken down temporarily, it should be marked with the down parameter</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">fail_timeout</span></pre> Parameter</h3>
	<p></p>
<pre><code class="linux" data-trim contenteditable>
	upstream myServers{
    server backend1.example.com:8080 max_fails=3 fail_timeout=30s;
	…
}
</code></pre>
	<aside class="notes">
<p>If NGINX fails to connect to or receive a response from a server, the server can be marked as unavailable for a period of time</p>
<p>Subsequent requests will not be routed to that server until it is no longer unavailable</p>
<p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">max_fails</span></pre> parameter on the server directive specifies how many failures before a server is marked as unavailable</p>
<p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">fail_timeout</span></pre> parameter on the server directive specifies how long a server is unavailable for</p>

	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">max_conns</span></pre> Parameter</h3>
	<pre><code class="linux" data-trim contenteditable>
	upstream backend {
	server backend1.example.com max_conns=3;
	server backend2.example.com;
}
</code></pre>
	<aside class="notes">
<p>Include max_conns parameter to set the max number of acceptable concurrent connections to an upstream.
Only available on the server directive of an upstream block.</p>
<p>But what happens when you exceed max_conns? (go to next slide)</p>

	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">queue</span></pre> Directive</h3>
	<pre><code class="linux" data-trim contenteditable>
		upstream backend {
	server backend1.example.com max_conns=3;
	server backend2.example.com;
		queue 100 timeout=70;
}
</code></pre>
	<aside class="notes">
<p>The queue directive places unprocessed requests in a queue when upstream reaches its max_conns limit.</p>
<p>The timeout parameter controls how long the server will wait before sending an error to client</p>

	</aside>
</section>

<section>
	<h3>Session Affinity</h3>
	<p>For applications that require state data on backend servers</p>
	<p>NGINX supports the following methods:</p>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">sticky cookie</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">sticky learn</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">sticky route</span></pre></li>
	</ul>
	<aside class="notes">
<p>Certain applications need to store session and state data on the upstream server
</p>
<p>Requests need to be routed to the same server to maintain application functionality
</p>
<p>To ensure requests get routed to the same server we use the sticky directive
Three methods</p>
<ul>
<li>Cookies</li>
<li>Sticky Routes</li>
<li>Sticky Learn</li>
</ul>
</p>

	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">sticky cookie</span></pre></h3>
	<p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">sticky cookie <i>name</i></span></pre></p>
	<pre><code class="linux" data-trim contenteditable>
	    upstream backendServers {
	server my.example1.com;
	server my.example2.com;
	
	sticky cookie my_srv expires=1h domain=example.com path=/cart;
}

</code></pre>
	<aside class="notes">
<p>Uses a HTTP cookie to identify the upstream server</p>
<p>Cookie is inserted by NGINX for the first response by the upstream server</p>
<p>Subsequent requests from the same client will be passed to the same server</p>
<p>If the server cannot be identified another server will be chosen based on the configured routing method</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">sticky learn</span></pre></h3>
	<p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">sticky cookie <i>name</i></span></pre></p>
	<pre><code class="linux" data-trim contenteditable>
	    upstream backendServers {
	server my.example1.com:8081;
	server my.example2.com:8082;
	
	sticky learn create=$upstream_cookie_sessionid lookup=$cookie_sessionid zone=client_sessions:1m; 
}

server {
	location / {
		proxy_pass http://backendServers;
}
}

</code></pre>
	<aside class="notes">
<p>Upstream server creates a session, usually via a HTTP cookie or a URL token, and places it in the response</p>
<p>NGINX will learn which cookie corresponds with which upstream server</p>
<p>When a client request contains a session cookie, NGINX will forward the request to the appropriate server</p>
<p>Note: Session identifier does not necessarily have to be a cookie</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">sticky learn</span></pre> Part 1</h3>
	<img src="assets/images/stickyLearn1.png" style="border:none; background:none; width:100%">
		  <aside class="notes">
	<aside class="notes"></aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">sticky learn</span></pre> Part 2</h3>
	<img src="assets/images/stickyLearn2.png" style="border:none; background:none; width:100%">
		  <aside class="notes">
	<aside class="notes"></aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">sticky learn</span></pre> Part 3</h3>
	<img src="assets/images/stickyLearn3.png" style="border:none; background:none; width:100%">
		  <aside class="notes">
	<aside class="notes"></aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">sticky route</span></pre></h3>
	<pre><code class="linux" data-trim contenteditable>	
upstream backend {
	zone backend 64k;
	server backend1.com route=tomcat1;
	server backend2.com route=tomcat2;
	server backend3.com route=tomcat3;

	sticky route $route_cookie $route_uri;
}
</code></pre>
		  <aside class="notes">
<p>Client is assigned a route from the backend proxied server, the first time it sends a request</p>
<p>Routing information is stored in a cookie or in the URI</p>
<p>On subsequent requests NGINX will examine the routing information to determine which server to send the request to</p>
<p>sticky directive uses the route parameter followed by multiple variables</p>
<p>The value of the variables will determine the route </p>
<p>The first non empty variable will be used to find the matching server
</p>
	</aside>
</section>

<section>
	<h3>Tomcat Example</h3>
	<img src="assets/images/tomcatExample.png" style="border:none; background:none; width:100%">
	<aside class="notes"></aside>
</section>

<section>
	<h3>Routing Variables</h3>
		<pre><code class="linux" data-trim contenteditable>
			map $cookie_JSESSIONID $route_cookie {
	~.+\.(?P&#60;route&#62;\w+)$ $route;
}

map $request_uri $route_uri {
	~JSESSIONID=.+\.(?P&#60;route&#62;\w+)$ $route;
}

</code></pre>
	<aside class="notes">
The values of $route_cookie and $route_uri can be determined through the use of a map
$cookie_JESSIONID looks at the value of the cookie called JESSIONID, which is present in the clients request
	</aside>
</section>

<section>
<section data-state="lab">
		  <h3>Lab 11.1: Tomcat Route</h3>
		  <ol>
		    <li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">myServers.conf</span></pre> in <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx/conf.d</span></pre></li>
		    <li>In the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">http</span></pre> context, create a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;"> log_format</span></pre> called <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;"> sticky</span></pre></li>
		    <li>Set the new log to:<pre><code class="linux" data-trim contenteditable>"\t Route URI: $route_uri \t Routing Cookie: $route_cookie \t All Cookies: $http_cookie \t ";
</code></pre> </li> 
<li> Add the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">sticky route</span></pre> directive with two variables: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$route_cookie $route_uri;</span></pre></li>
<li>Change the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">access_log</span</pre> format to the new "sticky" <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">log_level</span></pre></li>
<li>Add the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">route</span></pre> parameter to each upstream like so: <pre><code class="linux" data-trim contenteditable>upstream myServers {
	zone backend 64k;
	server &#60;backend_url&#62;:8080 route=backend1;
	server &#60;backend_url&#62;:8080 route=backend2;
	server &#60;backend_url&#62;:8080 route=backend3;
}
</code></pre> <span style="color:rgb(240,168,40);"><small>ask your instructor about changing the upstream backend urls!!!</small></span></li>
		</ol>
		  <aside class ="notes">
		  	<p>Note to instructor, if you haven't already please spinup the following Tomcat instances that are already pre-configured with the jvmRoute parameter</p>
		  	<p>Command to access AMI (assuming you have the public key)</p>:
		  	<pre><code class="linux" data-trim contenteditable>
		  		ssh -i AWS_service_rocket_key.pub ec2-user@ec2-54-196-159-75.compute-1.amazonaws.com
		  	</pre></code>
		  	<p>Spinup the following machines:</p>
		  	<pre><code class="linux" data-trim contenteditable>
		  		ngx-launch-class ubuntu-backend1
ngx-launch-class ubuntu-backend2
ngx-launch-class ubuntu-backend3
		  	</code></pre>
		  	<p>Copy the URL for each machine and give it to the students. You won't have to log into any of these machines so don't worry about the student numbers and passwords</p>
		  	<p>Lab Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
        log_format sticky  "$request \t Upstream: $upstream_addr \t Route URI: $route_uri \t Routing Cookie: $route_cookie \t All Cookies: $http_cookie \t ";

upstream myServers {
	server &#60;backend1&#62; route=jvmRoute1;
	server &#60;backend2&#62; route=jvmRoute2;
	server &#60;backend3&#62; route=jvmRoute3;

	sticky $route_cookie $route_uri;
}

map $cookie_jsessionid $route_cookie { 	
	~.+\.(?P&#60;route&#62;\w+)$ $route; 
}

map $request_uri $route_uri { 	
	~jsessionid=.+\.(?P&#60;route&#62;\w+)$ $route; 
}

server {
	listen 8080;
	...
	access_log /var/log/nginx/upstream.access.log sticky;
}


		  	</pre></code>
</aside>
		</section>

<section data-state="lab">
		  <h3>Lab 11.2: Tomcat Route Test</h3>
		  <ol>
		    <li>In your shell, make the following <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">curl</span></pre> requests:<pre><code class="linux" data-trim contenteditable>curl http://&#60;localhost&#62;:8080</code></pre></li>
		    <li>In a separate shell, run a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">tail -f</span></pre> command on your <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream_access.log</span></pre></li>
		    <li>Do you notice the IP address changing?</li>
		    <li>Open a browser, and step through the app via the following URI: <pre><code class="linux" data-trim contenteditable>&#60;localhost&#62;/examples/servlets/servlet/SessionExample</code></pre></li>
		    <li>Execute the application, and refresh your browser several times. What can you observe in the log now? Which IP address is the request hitting?</li>
		</ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<p>You can test the below URIs in a browser (recommended so you can show students the source code once you hit the SessionExample), or you can use the curl requests below.</p>
		  	<p>Make sure you run a tail command to show the new log_format in a separate or tabbed shell</p>
		  	<pre><code class="linux" data-trim contenteditable>
		  		sudo tail -f /var/log/nginx/upstream.access.log


      curl http://localhost:8080/
      curl http://localhost:8080/examples/
      curl http://localhost:8080/examples/servlets/
      curl http://localhost:8080/examples/servlets/servlet/
      curl http://localhost:8080/examples/servlets/servlet/SessionExample/
		  	</pre></code>
</aside>
		</section>
	</section>
<!--Next Section-->
		<section data-background="rgb(20, 149, 62)">
                  <h2>Live Activity Monitoring</h2>
                 </section>

                 <section>
          <h3>Module Objectives</h3>
             <p>This module enables you to:</p>
                <ul>
                <li>Use the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status</span></pre> directive to get server metrics</li>
                <li>Configure <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">health_check</span></pre> to monitor the availability of your upstream servers</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">status</span></pre> Directive</h3>
	<pre><code class="linux" data-trim contenteditable>
      server {
    listen 8080;

    location = /status{
	    status;
    }
}
		  	</pre></code>
	<aside class="notes">
<p>The HTTP status Module provides directives that facilitates live activity monitoring of your NGINX server
Load and performance metrics are provided through JSON
Can integrate with live dashboards or other third party monitoring tools </p>

<p>To set up the status Handler:</p>
<ul>
	<li>Setup a prefix location block with a URI that will be used to access the metric data
</li>
	<li>Specify the status directive inside the location block with absolute matching</li>
	<li>In the Example Code: NGINX responds to requests for <server>:8080/status with a JSON document containing the load and performance metrics of all virtual servers. a status.html will load that data into the default status page</li>
</ul>

	</aside>
</section>

<section>
	<h3>Securing the Status Request</h3>
	<pre><code class="linux" data-trim contenteditable>
      location = /status{
    allow 192.168.0.0/16; 
    deny all; # deny access from everywhere else 

    status; 
}

		  	</pre></code>
	<aside class="notes">
<p>For security best practices it is advisable to restrict the status location context to only requests from your internal network
</p>
	</aside>
</section>

<section>
	<h3>Default Status Page</h3>
	<p>NGINX Plus contains an html page that parses JSON</p>
	<p>The page is located at <strong>/usr/share/nginx/html/status.html</strong></p>
	<img src="assets/images/statusPage.png" style="border:none; background:none; width:100%">
	<aside class="notes">
<p>NGINX Plus contains a default status.html page to parse the JSON document and present the metrics in a more user friendly view</p>
<p>Page is located at /usr/share/nginx/html/status.html</p>
<p>To enable access to the page, configure a server block with root /usr/share/nginx/html and configure a location block with the status directive</p>

	</aside>
</section>

<section>
	<h3>Server Zones</h3>
	<div style="float:left;width:50%;padding-left:0px;">
	<pre><code class="linux" data-trim contenteditable>
	server {
	listen 8081;
	root /server/backend1;
	status_zone apac;
	}

server {
	listen 8082;
	root /server/backend2;
	status_zone apac;
}

server {
	listen 8083;
	root /server/backend3;
	status_zone us;
}
	</code></pre></div>

	<div style="float:right;width:45%;padding-right:0px;">
<p>Individual servers zones displayed in status.html:</p>
<img src="assets/images/serverZone.png" style="border:none; background:none; width:100%">
</div>
	<aside class="notes">
<p>Defines which servers you want to see individual statistics for in the status report</p>
<p>Multiple servers can be aggregated into one status zone</p>
<p>Use the status_zone directive on an individual server block</p>
<p>Use the zone directive for upstream blocks to define a shared memory zone.</p>
<p>Example</p>
<ul>
<li>status_zone apac;</li>
<li>zone backend 64k;</li>
</ul>

	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">zone</span></pre> Directive</h3>
	<p>Shared memory zone makes upstream dynamically configurable</p>
	<p>Allows worker processes to share counter information</p>
	<pre><code class="linux" data-trim contenteditable>
		upstream myServers {	
    zone backend 64k;		
	server backend1;	
	server backend2;	
	server backend3;
	}
	</code></pre>
	<aside class="notes">
<ul>
	<li>For upstream groups, the shared memory zone is required for health_checks, status module, upstream_conf, and resolver directives. To enable the shared memory zone we specify the "zone" directive</li>
<li>Basically, the worker processes will use this zone to share counters for key values, if no zone directive is specified then each worker process keeps its own copy of server configurations along with it's own set of counters.</li>
<li>What are counters might you ask?</li>
<li> The counters include the current number of connections to each server in the group and the number of failed attempts to pass a request to a server. As a result, the server group configuration isn’t changeable.</li>

<li>If the upstream directive does include the zone directive, the configuration of the server group is placed in a memory area shared among all worker processes. This scenario is dynamically configurable, because the worker processes access the same copy of the group configuration and utilize the same related counters.</li>

<li>For example, if the configuration of a group is not shared, each worker process maintains its own counter for failed attempts to pass a request to a server (see the max_fails parameter). In this case, each request gets to only one worker process. When the worker process that is selected to process a request fails to transmit the request to a server, other worker processes don’t know anything about it. While some worker process can consider a server unavailable, others may still send requests to this server. For a server to be definitively considered unavailable, max_fails multiplied by the number of workers processes of failed attempts should happen within the timeframe set by fail_timeout. On the other hand, the zone directive guarantees the expected behavior.</li>


</ul>
	</aside>
</section>

<section>
<section data-state="lab">
		  <h3>Lab 12.1: Define a Status Page</h3>
		  <ol>
		    <li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">myServers.conf</span></pre> located in <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/etc/nginx/conf.d/</span></pre></li>
 <li>In a new <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre> context that listens on <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">9090</span></pre> with a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">root</span></pre> location <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/usr/share/nginx/html;</span></pre>
</li>
		    <li>Add a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location</span></pre> prefix with an exact match <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">= /status</span></pre>, and the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status</span></pre> directive in this location block</li>
		    <li>Save and reload NGINX</li>
		    <li>Open a browser and access the following URI: <pre><code class="linux" data-trim contenteditable>http://&#60;server&#62;:9090/status.html</code></pre></li>
		    <li>Notice anything strange in the GUI?</li>
		</ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
server {
	listen 9090;
	root /usr/share/nginx/html;

	location = /status {
		status;
    }
}
		  	</pre></code>
</aside>
		</section>

		<section data-state="lab">
		  <h3>Lab 12.2: Define Server Zones</h3>
		  <ol>
		    <li>In <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">backends.conf</span></pre>, specify a server zone for each server by using the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status_zone</span></pre> directive</li>
		    <li>Open<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server1.conf</span></pre> and define a<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status_zone</span></pre></li>
		    <li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server2.conf</span></pre> and define a<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status_zone</span></pre></li>
		    <li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">myServers.conf</span></pre> and specify a shared memory zone in your <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream</span></pre> block with a size of <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">64k</span></pre></li>
		    <li>Save and reload NGINX</li>
		    <li> Refresh your browser listening on <pre><code class="linux" data-trim contenteditable>http://&#60;server&#62;:9090/status.html</code></pre></li>
		</ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
server {
    listen 8081;
    root /data/backend1;
    status_zone backend1;
}
server {
    listen 8082;
    root /data/backend2;
    status_zone backend2;
}
server {
	listen 8083;
	root /data/backend3;
	status_zone backend3;
}
      
		  	</pre></code>
</aside>
		</section>
	</section>

<section>
	<h3>Server <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">health_check</span></pre></h3>
	<p>A request sent to upstream to check status based on conditions</p>
	<pre><code class="linux" data-trim contenteditable>
		upstream myUpstreams {
		zone backend 64k;

		server localhost:8081 weight=1;
		server localhost:8082 weight=4;
		server localhost:8083 weight=7;
	}

	server {
	    listen 8080;
	    error_log /var/log/nginx/upstream_error.log info;

	    location / {
	        proxy_pass http://myUpstreams;
	        health_check;
	}
}
	</code></pre>
	<aside class="notes">
<p>A Health Check is a special request sent to servers in a server group, to check for their availability based on a defined set of conditions</p>
<p>If a server fails a health check it will be considered unavailable and will not receive client requests
</p>
<p>Requests are sent every 5 seconds by default
Uses the zone directive and health_check directive
</p>

	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">health_check</span></pre> Parameters</h3>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">interval</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">fails</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">passes</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">uri</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">match</span></pre></li>
	</ul>
	<aside class="notes">
		<ul>
			<li>interval sets the interval between two consecutive health checks, by default, 5 seconds;</li>
<li>fails sets the number of consecutive failed health checks of a particular server after which this server will be considered unhealthy, by default, 1;</li>
<li>passes sets the number of consecutive passed health checks of a particular server after which the server will be considered healthy, by default, 1;</li>
<li>uri defines the URI used in health check requests, by default, “/”;</li>

</ul>

<p>Question – what difference does the uri make if we don’t use the default? Default is / which will test against the index page of the root</p>
<p>Custom URI allows us to setup a specific status page with which we can hit. We can then use that page to mark a server for maintenance or upgrade</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">match</span></pre> Block</h3>
<p>Block directive that defines conditions for:<pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">health_check</span></pre></p>
<p>Conditions can be based on:</p>
<ul>
	<li>Response Codes</li>
	<li>Header Values</li>
	<li>Text body of documents</li>
</ul>
	<aside class="notes">
<p>Note: that if you decide to use the text body of a page, it will only match up until the first 256kb</p>
<p>Also, if you include multiple conditions in your health_check, ALL of them must be satisfied in order for the check to pass</p>
<p>Can be used in HTTP and Stream context, but health_checks for TCP/UDP are a little different in terms of syntax</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">match</span></pre> Directives</h3>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status</span></pre>
			<ul>
				<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status 200</span></pre></li>
				<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status ! 403</span></pre></li>
				<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status 200-399</span></pre></li>
			</ul>
		</li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">header</span></pre>
			<ul>
				<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">header Content-Type = text/html</span></pre></li>
				<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">header Cache-Control</span></pre></li>
			</ul>
		</li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">body</span></pre>
			<ul>
				<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">body ~ "Hellow World"</span></pre></li>
				<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">body !~ "hello world"</span></pre></li>
			</ul>
				</li>
			</ul>
	<aside class="notes">
<p>status checks the response code from the server. Can specify a range, or check against a value</p>
<p>Checks the presence and value of a specified HTTP header field in the response</p>
<p>checks text in body and matches against a regex</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">match</span></pre> Example</h3>
<pre><code class="linux" data-trim contenteditable>
	server {
    location / {
    proxy_pass http://myServers;
    health_check match=conditions fails=2;
    }
}
    match conditions {
    status 200;
    header Content-Type = text/html;
    body !~ “maintenance”;
}
</pre></code>
	<aside class="notes"></aside>
</section>

<section>
<section data-state="lab">
		  <h3>Lab 13.1: Server Maintenance</h3>
		  <ol>
		    <li>Open the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">myServers.conf</span></pre>, file</li>
		    <li>Change your upstream <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre> entries back to <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">localhost:8081, localhost:8082, localhost:8083</span></pre></li>
		    <li>Define a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">match</span></pre> block called <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">health_conditions</span></pre> with the following directives:
		    	<pre><code class="linux" data-trim contenteditable>
		    		match health_conditions {
    status 200-399;
    header Content-Type = text/html;
    body !~ maintenance;
}
		    		</code></pre>
		    </li>
		</ol>
		  <aside class ="notes">
		  	<p>Solution</p>
		  	<pre><code class="linux" data-trim contenteditable>
      match health_conditions {
    status 200-399;
    header Content-Type = text/html;
    body !~ maintenance;
}
		  	</pre></code>
</aside>
		</section>
		<section data-state="lab">
			<h3>Lab 13.2: Server Maintenance Continued</h3>
			<ol>
			 <li>In the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location</span></pre> prefix that matches all requests, add the following <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">match</span></pre> parameters:
		    	<pre><code class="linux" data-trim contenteditable>
		    		location / {
    proxy_pass http://myServers;
    health_check match=health_conditions
    fails=2
    uri=/health/test.html;
}
		    		</code></pre>
		    </li>
		    <li>Save and reload NGINX</li>
		    <li> Refresh your browser listening on <pre><code class="linux" data-trim contenteditable>http://&#60;server&#62;:9090/status.html</code></pre></li>
		    <li>A server is down. To fix it, change the text "maintenance" in the test.html for backend3</li>
		    <pre><code class="linux" data-trim contenteditable>
		    	$ cd /data/server2/backend3/health/
		    	$ sudo vim test.html
		    		</code></pre>
		</ol>
		<aside class="notes">
<pre><code class="linux" data-trim contenteditable>
      match health_conditions {
    status 200-399;
    header Content-Type = text/html;
    body !~ maintenance;
}
...

server {
	listen 8080;
	...

	location / {
        proxy_pass http://myServers;
        health_check match=health_conditions fails=2uri=/health/test.html;
    }
}
		  	</pre></code>
		</aside>
	</section>
</section>

<!--Next Section-->
		<section data-background="rgb(20, 149, 62)">
                  <h2>Caching</h2>
                 </section>

                 <section>
                  <h3>Module Objectives</h3>
                  <p>This module enables you to:</p>
                  <ul>
                    <li>Define a reverse proxy cache for your upstream and other servers</li>
                    <li>Purge old or stale content from the cache</li>
                    <li>Identify other cache control techniques</li>
		  </ul>
                  <aside class="notes"></aside>
                </section>
<section>

	<h3>Reverse Proxy and Caching</h3>
	<p>Common use case to have NGINX in front, caching static resources to improve performance</p>
	<p>To compose a cache:</p>
		<ul>
			<li>Define a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">cache_path</span></pre></li>
			<li>Configure the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_pass</span></pre></li>
			<li>Reference the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">cache_key</span></pre></li>
			<li>Validate the cacheability of content using <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache_valid</span></pre></li>
		</ul>
	<aside class="notes">
<p>NGINX uses a hybrid persistent cache that stores the content on disc, and the metadata about the cache in the shared memory zone. In order to instrument a cache, we must:</p>
<ul>
	<li>Define a cache using the proxy_cache_path directive</li>
	<li>Define a proxy_pass in order to set the proxy_cache conditions for backend responses</li>
	<li>Reference a cache_key which is used to create the md5 hash (metadata), in order to store this information in the shared memory zone</li>
	<li>Validate the cacheability (usually dicated by the Cache-Control headers of the origin server) by specificy which responses are cached via proxy_cache_valid</li>
	</aside>
</section>

<section>
	<h3>Configuring the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">proxy_cache</span></pre></h3>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache_key</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache</span></pre></li>
	</ul>
	<pre><code class="linux" data-trim contenteditable>
		location / {
    proxy_pass http://application.com:8080;

    proxy_cache_key "$scheme$host$request_uri";
    proxy_cache my-cache;
    proxy_cache_valid 1m;
    proxy_cache_valid 404 1m;
}
</code></pre>
	<aside class="notes">
<p>We can use the proxy_cache_key directive to map our stored cached values. This same key is used to check whether a request can be served from the cache based on those stored values.</p>
<p>In the below example we are setting this to a combination of the scheme (which is http or https), the request method (which can be post or get), as well as the requested host and URI.</p>

<p>So for example if we make a request to http://www.example.com/images/logo.png, the first time we make that request NGINX will cache it. The second time we make the same request, nginx will check for a match against the cache_key, if there’s a match nginx will serve the request from the cache rather than proxy to the backend.</p>

<p>The proxy_cache directive represents the shared memory zone used for caching the md5 hash. The name specified must match the name we specified in the proxy_cache_path directive</p>
	</aside>
</section>

<section>
	<h3>Validating the Cache</h3>

	<pre><code class="linux" data-trim contenteditable>
		location / {
    proxy_cache_valid any 1m;
    proxy_cache_valid 404 1m;
}
</code></pre>
	<aside class="notes">
<p>Proxy_cache_valid will set a duration at which NGINX will respond with a 200, 301, or 302 HTTP response code for a set time. In the second example we can set proxy_cache_valide to return a 404 response code after a set time.</p>
<p>You need to have the poxy_cache_valid for the cache to actually kick in.</p>
	</aside>
</section>

<section>
	<h3>Passing Headers</h3>
	<pre><code class="linux" data-trim contenteditable>
		proxy_set_header	Host	$host;
proxy_set_header	X-Real-IP	$remote_addr;
proxy_set_header	X-Forwarded-For	$proxy_add_x_forwarded_for;

	</code></pre>
	<aside class="notes">
<p>Use the proxy_set_header to redefine the request headers that are passed to the server. A lot of times when we use a reverse proxy our backend server is going to see that the request came from a proxied server, in other words the request came from a proxied server’s IP address. A popular use case for the proxy_set_header directive is to set the header to the client’s IP address instead.</p>

<p>(highlight example to show this i.e. host = domain, remote addr = client’s ip, proxy_add_x_forward appends the ip’s address to the header)</p>

<p>$proxy_add_x_forward_for is for a multi-layered reverse proxy. RESEARCH THIS</p>

<p>Build example to add content i.e. </p>

	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">add_header</span></pre> Directive</h3>
	<pre><code class="linux" data-trim contenteditable>
		server {
[…]
    add_header X-Proxy-Cache $upstream_cache_status;

    location / {
    proxy_cache myCache;
    proxy_pass http://localhost:8081;
	}
}
	</code></pre>
	<aside class="notes">
<p>Useful to instrument an upstream cache.
Adds fields to response headers provided that the response is a valid http code (200, 301, 404 etc.)</p>
<p>Multiple add_header directives can exist in multiple contexts and will inherit the previous level as long as there is no add_header directive defined on current level.
Syntax: add_header "name value"</p>

	</aside>
</section>

<section>
<section data-state="lab">
			<h3>Lab 14.1: Proxy Cache</h3>
			<ol>
			 <li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server1.conf</span></pre></li>
			 <li>Define a cache path in the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">http</span></pre> context:
		    	<pre><code class="linux" data-trim contenteditable>
		    		proxy_cache_path /data/nginx/cache levels=1:2
keys_zone=img_cache:20m inactive=5m;
		    		</code></pre>
		    </li>
		    <li>In the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre> context, set the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache_key</span></pre> to the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$scheme</span></pre>, <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$host</span></pre>, and <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">$request_uri</span></pre></li>
		    <li>Add the following in your <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server</span></pre>context</li>
		    <pre><code class="linux" data-trim contenteditable>
		    proxy_cache_key $scheme$host$request_uri;
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
</code></pre>
		</ol>
	</section>
<section data-state="lab">
			<h3>Lab 14.2: Proxy Cache Continued</h3>
			<ol>
			<li>Set the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache</span></pre> in the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">application1</span></pre> prefix, and set the validation of the cache for 10 minutes.</li>
			<pre><code class="linux" data-trim contenteditable>
				location /application1 {
	proxy_cache img_cache;
	proxy_cache_valid 10m;
	proxy_pass http://localhost:90/sampleApp			</code></pre>
		    <li>Save and reload NGINX</li>
		    <li>Reload NGINX and make a request to <pre><code class="linux" data-trim contenteditable>http://&#60;server&#62;/application1</code></pre></li>
		    <li>Hit refresh multiple times and then check your status.html in a separate tab. Notice the cache icon is now “warm” and the hit ratio is increasing</li>
		</ol>
		    <aside class="notes">
		    	<p>Solution:</p>
		    	<pre><code class="linux" data-trim contenteditable>
		    		proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=img_cache:20m inactive=5m;
…
proxy_cache_key $scheme$host$request_uri;
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
...
location /application1 {
	proxy_cache img_cache;
	proxy_cache_valid 10m;
	proxy_pass http://localhost:90/sampleApp;

		    	</code></pre>
		    </aside>
		</section>

<section data-state="lab">
			<h3>Lab 15.1: Proxy Upstream Cache</h3>
			<ol>
			<li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">Open /etc/nginx/conf.d/myServers.conf
</span></pre></li>
<li> Create a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache_path</span></pre> with a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">keys_zone</span></pre> named <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstreamCache</span></pre> that lasts for:
<ul>
<li>10 minutes</li>
<li>Has a max size of 60mb</li>
<li>Timeouts after 60 minutes</li>
</ul>
</li>
</ol>
<aside class="notes"></aside>
</section>


<section data-state="lab">
			<h3>Lab 15.2: Proxy Upstream Cache Continued</h3>
			<ol>
<li>Set the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_set_header</span></pre> to forward the client host and IP</li>
<li>Use the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">add_header</span></pre> directive with the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">X-Proxy-Cache</span></pre> response header to return the upstream status</li>
<li>Add <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache</span></pre> to the proxying location</li>
<li>Save and reload NGINX</li>
<li>Make a request to your upstream and notice the second cache in your status.html</li>
<li>Try making a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">curl</span></pre> request? What do you see with the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">-I</span></pre> parameter?</li>
		</ol>
		    <aside class="notes">
		    	<p>Solution:</p>
		    	<pre><code class="linux" data-trim contenteditable>
		    		proxy_cache_path /data/nginx/cache2 levels=1:2 keys_zone=upstreamCache:10m max_size=60m inactive=60m;
…
proxy_set_header Host $host;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
add_header X-Proxy-Cache $upstream_cache_status;
location / {
	proxy_cache upstreamCache;
	proxy_cache_valid 10m;
	proxy_pass http://myServers;

		    	</code></pre>
		    </aside>
		</section>
	</section>


<section>
<section>
	<h3>Caching Resources</h3>
	<p>Directives that control cached responses:</p>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache_min_uses</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache_methods</span></pre></li>
	</ul>
	<p>Caching limit rates:</p>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache_bypass</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_no_cache</span></pre></li>
	</ul>
	<p></p>
	<div style="text-align:center;"><small>Documentation: <a href="https://www.nginx.com/resources/admin-guide/content-caching/" target="_blank">Cache Admin Guide</a></small></div>

	<aside class="notes"></aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">proxy_cache_min_uses</span></pre></h3>
<pre><code class="linux" data-trim contenteditable>
		server {
    proxy_cache myCache;
    proxy_pass http://localhost:8081;
    proxy_cache_min_uses 5;
}
</code></pre>

	<aside class="notes">
Proxy_cache_min_uses sets the number of times an item must be requested by clients before NGINX caches it.
 By default proxy_cache_min_uses is set to 1.
Further requests are evicted from cache when not accessed within the timeout duration or when max_size upper limit is reached.

This directive counts the number of requests after which the response from the upstream is cached.
This directive is useful if you have a lot of concurrent requests and you don’t want to cache every response or if your cache is constantly hitting it’s upper limits and you want to regulate the most frequently accessed  items.


	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">cache_methods</span></pre> and <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">no_cache</span></pre></h3>
	<p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache_methods &#60;REQUEST METHOD&#62;</span></pre></p>
	<p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_no_cache $arg</span></pre></p>
<pre><code class="linux" data-trim contenteditable>
	map $request_uri $no_cache;
    /default	0;
    /test		1;

server {
	proxy_cache_methods GET HEAD POST;
	proxy_no_cache $no_cache;
}

</code></pre>	

	<aside class="notes">
Proxy_cache methods is recommended when you want to cache additional request methods beyond GET and HEAD. 
Proxy_no_cache is recommended if there’s a request URI that you don’t want to be cached at all. Like perhaps it’s a location that requires a re-aunthentication or re-validation
	</aside>
</section>
</section>

<section>
	<h3>Cache Manager and Loader</h3>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">loader_threshold</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">loader_files</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">loader_sleeps</span></pre></li>
	</ul>
	<pre><code class="linux" data-trim contenteditable>
		proxy_cache_path /data/nginx/cache keys_zone=one:10m loader_threshold=300 loader_files=200;
	</code></pre>
	<aside class="notes">
		<p>Cache Manager is a background process NGINX uses to prune the cache (evict old data based on max-age) that's dictated by your max_size, and timeout parameters in proxy_cache_path</p>
		
<p>A cache loader spins up at startup and runs once, loading metadata onto disk in small chunks: 100 files at a time, sandboxed to 200 ms, and then pausing for 50 ms in between, and then repeating until it’s worked its way through the entire cache and populated the shared memory segment.</p>

<p>The cache loader then exits and doesn’t need to run again unless NGINX is restarted or reconfigured and the shared memory segment needs to be reinitialized.</p>

<p>You can tune the operation of the cache loader, which may be appropriate if you have very fast disks and a light load. You can make it run faster or perhaps you might want to wind it back a little bit if you’re storing a cache with a huge number of files and slow disks and you don’t want the cache loader to use excessive amounts of CPU when NGINX starts up.</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">proxy_cache_purge</span></pre> Directive</h3>
	<p>Allows you to remove full cache entries that match a configured value.</p>
	<pre><code class="linux" data-trim contenteditable>
		server {
    proxy_cache myCache;
    proxy_pass http://localhost:8081;
    proxy_cache_purge $purge_method;
}

</code></pre>
	<aside class="notes">
<p>One side effect of caching content is that content updates may not terminate the existing content in a client’s browser.</p>
<p>proxy_cache_purge allows you to remove full cache entries that match a configured value.
Syntax: proxy_cache_purge "string"</p>

	</aside>
</section>

<section>
	<h3>Purge Methods</h3>
	<p>Partial Purge</p>
	<ul>
		<li>use <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">curl</span></pre> command to send <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">PURGE HTTP</span></pre> request, <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">map</span></pre> evaluates request and enables the directive</li>
	</ul>
	<p>Full Purge</p>
	<ul>
		<li>turn <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">purger</span></pre> parameter on in the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">proxy_cache_path</span></pre>, all wildcard pages will also be purged</li>
	</ul>
	<aside class="notes">
<p>Partial Purge: The map directive stores the PURGE HTTP request, then references the request method in a specific caching location.
</p>
<p>Full Purge: In addition to purging the specific location, by enabling purger=on all files matching the wildcard key (*) are completely removed from cache.</p>
	</aside>
</section>

<section>
	<h3>HTTP PURGE Example</h3>

	<p>Request: <pre><code class="bash" data-trim contenteditable>$curl –X PURGE –D – “http://www.mysite.com"</code></pre></p>

	<pre><code class="linux" data-trim contenteditable>
		# setting the default purge method will only delete matching URLs.
map $request_method $purge_method {
    PURGE 1;
    default 0;
	}
server {
    listen 80;
    server_name www.mysite.com
    proxy_cache myCache;
    proxy_pass http://localhost:8081;
    proxy_cache_purge $purge_method;
}

	</code></pre>
	<aside class="notes"></aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">purger</span></pre> Example</h3>

	<p>Request: <pre><code class="bash" data-trim contenteditable>$curl –X PURGE –D – “http://www.mysite.com/*"</code></pre></p>

	<pre><code class="linux" data-trim contenteditable>
		proxy_cache_path /data/nginx/cache levels=1:2 keys=myCache:10m purger=on;

server {
    listen 80;
    server_name www.mysite.com;
    location / {

        proxy_cache_purge $purge_method;
    }
}

	</code></pre>
	<aside class="notes"></aside>
</section>

<section data-state="lab">
			<h3>Lab 16.1: Configure Cache Purge</h3>
			<ol>
<li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">myServers.conf</span></pre> and use a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">map</span></pre> to create a custom variable called <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">purge_method</span></pre> that depends on the predefined <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">request_method</span></pre></li>
<li>In the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">location</span></pre> where caching occurs, specify a condition for the cache purge request.</li>
<li>Save and reload NGINX</li>
<li>Send the purge command using the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">curl</span></pre> command, your machine url, and port. E.g. <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">http://&#60;server&#62;:8080</span></pre>.</li>
<li>A successful purge should return an <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">HTTP 204</span></pre> code (no content).</li>
		</ol>
		    <aside class="notes">
		    	<p>Solution:</p>
		    	<pre><code class="linux" data-trim contenteditable>
		    		proxy_cache_path /data/nginx/cache2 levels=1:2 keys_zone=upstreamCache:10m max_size=60m inactive=60m;
…
proxy_set_header Host $host;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
add_header X-Proxy-Cache $upstream_cache_status;
location / {
	proxy_cache upstreamCache;
	proxy_cache_valid 10m;
	proxy_pass http://myServers;

		    	</code></pre>
		    </aside>
		</section>


<!--Next Section-->
<section data-background="rgb(20, 149, 62)">
    <h2>Compression</h2>
</section>

<section>
	<h3>HTTP <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">gzip</span></pre> Module</h3>
	<p>Key Directives:</p>
	<ul>
		<li>gzip</li>
		<li>gzip_types</li>
		<li>gzip_proxied</li>
	</ul>
	<aside class="notes">
<p>Provides Gzip capabilities so that responses from NGINX are compressed to reduce file size</p>
<p>A number of directives are used to control gzip settings</p>
<p>Directives can be used in the http, server and location contexts</p>
<p>NGINX has gzip compression capabilities and there are a number of directives to control the settings. The directives can be used in http, server, and location contexts.
</p>

	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">gzip</span></pre> Example</h3>
	<pre><code class="linux" data-trim contenteditable>
		http {
    gzip on;
    gzip_types text/plain text/css;
    gzip_proxied any;
}
	</code></pre>
	<aside class="notes">
		<ul>
<li>Enable gzip</li>
<li>Apply gzip for text, html and CSS</li>
<li>Enable gzip compression for any proxied request</li>


<p>It is not advisable to enable gzip for binary content types such as images, word documents or videos
MIME type of text/html is always compressed</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">gzip_min_length</span></pre></h3>
	<p>Specifies the minimum length of the response to compress</p>
	<pre><code class="linux" data-trim contenteditable>
		gzip_min_length 1000;
	</code></pre>
	<aside class="notes">
Measured in bytes, the default is 20
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">gzip_proxied</span></pre></h3>
	<p>NGINX doesn't compress proxied requests by default, <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">gzip_proxied</span></pre> instructs NGINX to check header fields</p>
<pre><code class="linux" data-trim contenteditable>
		server {
gzip on;
gzip_types text/plain application/xml;
gzip_proxied no-cache no-store private expired auth;
gzip_min_length 1000;
}
	</code></pre>

	<aside class="notes">
<p>By default, NGINX does not compress responses to proxied requests (requests that come from the proxy server). The fact that a request comes from a proxy server is determined by the presence of the Via header field in the request.</p> <p>To configure compression of these responses, use the gzip_proxied directive. The directive has a number of parameters specifying which kinds of proxied requests NGINX should compress. </p>

<p>For example, it is reasonable to compress responses only to requests that will not be cached on the proxy server.</p>

<p>For this purpose the gzip_proxied directive has parameters that instruct NGINX to check the Cache-Control header field in a response and compress the response if the value is no-cache, no-store, or private. In addition, you must include the expired parameter to check the value of the Expires header field.</p>

 <p>These parameters are set in the following example, along with the auth parameter, which checks for the presence of the Authorization header field (an authorized response is specific to the end user and is not typically cached):</p>
	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">gzip_static</span></pre></h3>
	<p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">gzip_static on | off</span></pre></p>

<pre><code class="linux" data-trim contenteditable>
		server { 
gzip on;
gzip_static on;
gzip_types text/plain application/xml; 
gzip_proxied no-cache no-store private expired auth; 
gzip_min_length 1000;  
}
	</code></pre>

	<aside class="notes">
<p>gzip_ static on | off</p>
<p>Sends a compressed version of a file to the client instead of the regular one, set the gzip_static directive to on within the appropriate context. </p>


<p>In this case, to service a request for /path/to/file, NGINX tries to find and send the file/path/to/file.gz.</p> <p>If the file doesn’t exist, or the client does not support gzip, NGINX sends the uncompressed version of the file.</p>

<p>Note that the gzip_static directive does not enable on-the-fly compression. It merely uses a file compressed beforehand by any compression tool. To compress content (and not only static content) at runtime, use the gzip directive.</p>
<p>This directive is defined in a separate module that might not be included in an open source NGINX build by default.</p>

	</aside>
</section>

<section>
	<h3>HTTP <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">gunzip</span></pre> Module</h3>
	<p>Decompresses client gzip responses, if gzip method isn't supported</p>
	<p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">gunzip_buffers <i>number</i> <i>size</i></span></pre></p>
	<pre><code class="linux" data-trim contenteditable>
		http {
gunzip on;
gunzip_buffers 32 4k;

	</code></pre>
	<aside class="notes">
<p>Best used when trying to store compressed data and reduce I/O overhead</p>
<p>gunzip on | off, enables or disables decompression</p>
<p>gunzip_buffers number size sets buffers used to decompress the response</p>

	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">gzip_vary</span></pre></h3>
	<p>Places the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">“Vary: Accept-Encoding”</span></pre> response header if both <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">gzip_static</span></pre> and <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">gunzip</span></pre> are active.</p>
<pre><code class="linux" data-trim contenteditable>
	server { 
	gzip on;
	gzip_vary on;
	gzip_types text/plain application/xml application/json; 
	gzip_proxied no-cache no-store private expired auth; 
	gzip_min_length 1000;  
	}
}
</code></pre>
<aside class="notes">
	<P>Imagine two clients: an old browser without compression, and a modern one with it. If they both request the same page, then depending on who sent the request first, the compressed or uncompressed version would be stored in the CDN or cache.</p>
	<p> Now the problems start: the old browser could ask for a regular “index.html” and get the cached, compressed version which to them will display as random junk data, or the new browser could get the cached, uncompressed version and try to “unzip” it. Bad news, either way.</p>

<p>By default gzip_vary is set to on with this reason in mind. It should be noted that in order to utilize gzip_static and gunzip directives effectively, it is best to ensure gzip_vary is enabled.</p>
	</aside>
</section>

 <!--Next Section-->
	<section data-background="rgb(20, 149, 62)">
        <h2>Dynamic Configuration</h2>
    </section>

    <section>
	<h3>Module Objectives</h3>
	<p>This module enables you to:</p>
	<ul>
		<li>Leverage NGINX API to dynamically configure server information</li>
		<li>Use the state directive to make changes persistent</li>
	</ul>
	<aside class="notes"></aside>
</section>

<section>
	<h3>Dynamic Configuration</h3>
	<p>Advantages:</p>
	<ul>
		<li>View, modify, and remove servers at runtime</li>
		<li>No need to reload NGINX to affect changes</li>

	</ul>
	<p>Disadvantages</p>
	<ul>
	<li>Runtime config is not saved to conf file</li>
	<li>Changes revert back to conf settings after reload (unless using <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">state</span></pre> directive)</li>
</ul>
	<aside class="notes"></aside>
</section>

<section>
	<h3>Shared Memory Zone</h3>
	<ul>
	<li>Required to make server dynamically configurable</li>
	<li>Distributes traffic more evenly</li>
	<li>Necessary for <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">state</span></pre> changes (covered later)</li>
	<aside class="notes">
<p>Requires shared memory zone defined in the upstream group (i.e. zone directive) </p>
<p>In NGINX, weights are managed independently per-worker process.  NGINX Plus uses a shared memory segment (the ‘zone’) for upstream data, so weights are shared between workers and traffic is distributed more accurately.
</p>

<p>NGINX Plus makes use of a shared memory segment that stores the configuration of the server group</p>
<p>Workers can use the same set of counters to keep track of server responses from the group</p>
<p>Traffic is distributed more accurately</p>
<p>Allows the server group to be dynamically configurable </p>
<p>Must be defined in order for health checks to be enabled</p>


	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">upstream_conf</span></pre> Directive</h3>

	<pre><code class="linux" data-trim contenteditable>
		upstream myServers {

		server localhost:8081;
		server localhost:8082;
	}

	server {
	    listen 8080;

	    location / {
	        proxy_pass http://myServers;
	}
	    location /upstream_conf {
	        upstream_conf;
	        allow 127.0.0.1;
	        deny all;
	}

}
	</code></pre>
	<aside class="notes">
<p>Define a location block to be used specifically for receive configuration requests</p>
<p>Secure the location block from external access
Specify the upstream_conf directive in that location block</p>
<p>Use the zone directive to define a shared memory zone in the upstream group of servers where you want to allow dynamic configuration</p>

	</aside>
</section>

<section>
	<h3><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">upstream_conf</span></pre> Parameters</h3>
	<p>Key Parameters:</p>
	<ul>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">add=</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">remove=</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">drain=</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream=name</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">server=address</span></pre></li>
		<li><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">id=number</span></pre></li>
	</ul>
	<aside class="notes">
<p>Requests are sent through a special HTTP INTERFACE using a GET method. Make sure to send a HTTP request to the location block where the upstream_conf directive is specified</p>
Append parameters to the HTTP requests
Key parameters

	</aside>
</section>

<section>
	<h3>Sending Requests</h3>
	<p>View and modify server details</p>
	<pre><code class="linux" data-trim contenteditable>
#View all primary servers in upstream group myServers
curl http://&#60;server&#62;:8080/upstream_conf?upstream=myServers

#View individual server detail in upstream group
curl http://&#60;server&#62;:8080/upstream_conf?upstream=myServers&#38;id=&#60;id number&#62;

	</code></pre>
	<aside class="notes">
<ul>
	<li>Use the upstream parameter to select the upstream server group</li>
<li>This will display all servers and their ID number</li>
<li>ID number is required for modifying a server</li>
<li>Select an individual server to modify with the ID</li>
<li>Each server property can be specified as a parameter</li>
</ul>

	</aside>
</section>

<section>
	<h3>Add and Remove Servers</h3>
	<pre><code class="linux" data-trim contenteditable>
		#Add a new server to the myServer group with address localhost:8083 and weight = 4
http://&#60;server&#62;:8080/upstream_conf?add=&#38;upstream=myServers&#38;server=localhost:8083&#38;weight=4

#Remove server with id=0 from the myServers upstream group
http://&#60;server&#62;:8080/upstream_conf?remove=&#38;upstream=myServers&#38;id=0
	</code></pre>
	<aside class="notes">
<p>First specify the add or remove parameter in the request</p>
	<p>Then indicate the server group where you want to add or remove the server</p>
	</aside>
</section>

<section>
	<h3>More Examples</h3>
	<pre><code class="linux" data-trim contenteditable>
		#Modify the server with id = 0 and set the weight to 5 and the max_fails parameter to 4
http://&#60;server&#62;:8080/upstream_conf?upstream=myServers&#38;id=0&#38;weight=5&#38;max_fails=4

#Modify the server with id = 0 and set the route parameter to tomcat1
http://&#60;server&#62;:8080/upstream_conf?upstream=myServers&#38;id=0&#38;route=tomcat1

#Modify the server with id = 0 and set the server address to newdomain.com
http://&#60;server&#62;:8080/upstream_conf?upstream=myServers&#38;id=0&#38;server=newdomain.com

	</code></pre>
	<aside class="notes"></aside>
</section>

<section>
	<h3>Using the Status Dashboard</h3>
	<img src="assets/images/status2.png" style="border:none; background:none; width:100%">
	<aside class="notes">
<p>Using the status JSON feed allows the sysadmin to add, edit, or remove servers using the GUI.</p>
<p>Use the pencil icon to edit server groups.</p>

	</aside>
</section>

<section data-state="lab">
			<h3>Lab 17: Dynamic Config</h3>
			<ol>
<li>Open <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">myServers.conf</span></pre> and add an <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream_conf</span></pre> location prefix in the same server block where the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status</span></pre> prefix is located.</li>
<li>Add the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream_conf</span></pre> directive inside the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream_conf prefix</span></pre></li>
<li>Open your browser and hit <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">http://server:9090/upstream_conf?upstream=myServers</span></pre>, note the id number of the first server</li>
<li>Use the API commands to <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">remove</span></pre> the server, then <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">add</span></pre> it back with a <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">weight</span></pre> of 5</li>
<li>Try using the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">status.html</span></pre> page to change server details</li>
		</ol>
		    <aside class="notes">
		    	<p>Solution:</p>
		    	<pre><code class="linux" data-trim contenteditable>
		    		7) /upstream_conf?remove=&#38;upstream=myServers&#38;id=0
8) /upstream_conf?add=&#38;upstream=myServers&#38;server=localhost:8081&#38;weight=5
9090/upstream_conf?down=&#38;upstream=myServers&#38;id=2
		    	</code></pre>
		    </aside>
		</section>

<section>
	<h3>Persistent Changes</h3>
	<p>For SDP protocols that allow automatic detection of devices and/or services, changes must persist across reloads</p>
	<ul>
		<div><small>Documentation:<a href="https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/" target="_blank"> Microservices architecture</a></small></div>
		<div><small>Demo:<a href="https://www.nginx.com/blog/service-discovery-with-nginx-plus-and-consul/" target="_blank"> Service Descovery with Consul</a></small></div>
	</ul>
	<aside class="notes">
<p>Service instances sometimes have dynamically assigned network locations and use SDPs (service discovery protocols) that allow automatic detection of devices/services.</p>
<p>In modern cloud-based applications, API invocation can’t rely on static network locations.</p>
<p>NGINX Plus’s On-the-fly reconfiguration API, allows changes made to configurations (i.e. new server locations, proxy bindings etc.) persist across restarts and reloads</p>

	</aside>
</section>

<section>
	<h3>state Directive</h3>
	<p><pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">state</span></pre> name MUST match <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">zone</span></pre> name</p>
	<p>Syntax: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">state <i>file/path.state</i></span></pre></p>
	<pre><code class="linux" data-trim contenteditable>
    upstream myServers {
    zone backend 64k;
    state /etc/nginx/conf.d/backend.state;
}
	</code></pre>
	<aside class="notes">
<p>As of NGINX Plus R8, use the state directive to make API changes persistent.</p>
<p>State directive names the file which NGINX Plus stores state information</p>
<p>Placed in upstream block.</p>
<p>Syntax: state file/path</p>
<p>State directive documentation: http://nginx.org/en/docs/http/ngx_http_upstream_module.html?_ga=1.69588178.319098687.1462830831#state</p>
	</aside>
</section>

<section data-state="lab">
			<h3>Lab 18: Persistent Dynamic Config</h3>
			<ol>
<li>Create a directory for <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">/var/lib/nginx/state</span></pre> and change ownership of the path like so:
<pre><code class="linux" data-trim contenteditable>
$ sudo mkdir -p /var/lib/nginx/state
$ sudo chown nginx:nginx /var/lib/nginx/state
</code></pre>
</li>

<li>Comment out the existing servers in the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">upstream</span></pre></li>
<li> Save NGINX and reload</li>
<li>Run in a new browser window enter the following urls:<pre><code class="linux" data-trim contenteditable>
	&#60;server&#62;:9090/upstream_conf?add=&#38;upstream=myServers&#38;server=127.0.0.1:8081&#38;weight=5
&#60;server&#62;:9090/upstream_conf?add=&#38;upstream=myServers&#38;server=127.0.0.1:8082&#38;weight=4
&#60;server&#62;:9090/upstream_conf?add=&#38;upstream=myServers&#38;server=127.0.0.1:8083&#38;weight=3
	</code></pre></li>
	<li>Go to your status.html page and dynamically edit these server details</li>
		</ol>
		    <aside class="notes">
		    	<p>Solution:</p>
		    	<pre>
		    </aside>
		</section>


    <!--Next Section-->
	<section data-background="rgb(20, 149, 62)">
        <h2>Installation</h2>
    </section>

    <section>
	<h3>Module Objective</h3>
	<p>This module will enable you to:</p>
	<ul>
		<li>Install NGINX from a binary distribution</li>
		<li>Compile binary from source code</li>
	<aside class="notes"></aside>
</section>
<section>
	<h3>CentOS, RHEL</h3>
	<ul>
		<li>Setup <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">yum</span></pre> repository</li>
		<li>Edit repo file to pull latest packages</li>
		<li>Update repo</li>
		<li>Install NGINX</li>
	</ul>
	<div style="text-align:center;"><small>Documentation: <a href="https://www.nginx.com/resources/admin-guide/installing-nginx-open-source/#prebuilt_redhat" target="_blank">CentOS/RHEL Install Guide</a></small></div>
	<aside class="notes">The big thing to remember when installing open source with CentOS or RHEL, besides using yum, is to choose between using a RHEL/CentOS default repo, or setting up your own EPEL repo, and adding the necessary baseURL in your repo file.</aside>
</section>

<section>
	<h3>Debian, Ubuntu</h3>
	<ul>
		<li>Authenticate repo signature</li>
		<li>Retrieve distribution components </li>
		<li>Resolve dependencies</li>
		<li>Install NGINX</li>
	</ul>
</section>

<section>
	<h3>NGINX Signing Key</h3>
	<pre><code class="linux" data-trim contenteditable>
		wget http://nginx.org/keys/nginx_singing.key
		sudo apt-key add nginx_signing.key
	</code></pre>
	<aside class="notes">
<p>Used to authenticate the NGINX repository signature and sign the NGINX packages</p>
<p>After downloading the key we will add it using the super user do command also known as sudo, to give us the necessary privileges.</p>
	</aside>
</section>

<section>
	<h3>Distribution URL</h3>
	<p>Edit the sources.list to retrieve correct distribution components</p>
	<pre><code class="linux" data-trim contenteditable>
#Open the sources.list file with vim
sudo vim /etc/apt/sources.list

#For Debian, append the following distribution URLs
deb http://nginx.org/packages/debian/ codename nginx 
deb-src http://nginx.org/packages/debian/ codename nginx 

#For Ubuntu
deb http://nginx.org/packages/ubuntu/ codename nginx 
deb-src http://nginx.org/packages/ubuntu/ codename nginx
</code></pre>
	<aside class="notes">
<p>The sources.list file tells the Apt program where to retireve distribution components and their source code</p>

<ul>
	<li>We need to append the sources.list file so that we can tell the apt program where to retrieve NGINX components.</li>
<li>Here is the sudo command you will use to append the file.</li>
<li>For us we will be using 14.04 in the course. It is important that you complete this step.</li>
<li>IF YOU USE THE APT-GET PROGRAM IT WILL DOWNLOAD THE UBUNTU distro, which may not be the latest stable release—hence why we ensure that we’re getting the most up-to-date packages directly from nginx.</li>
<li>The sources.list file is located in:
sudo vim /etc/apt/sources.list
<li>Append the sources.list file: deb http://nginx.org/packages/ubuntu/ trusty nginx</li>
<li>deb-src http://nginx.org/packages/ubuntu/ trusty nginx</li>
</ul>
	</aside>
</section>

<section>
	<h3>Distribution Codename Reference</h3>
	<div style="float:left;width:45%;padding-left:0px;">
		<p>Debian:</p>
		<ul>
			<li>7.x - wheezy</li>
			<li>6.x - squeeze</li>
		</ul>
		<p>Ubuntu:</p>
		<ul>
			<li>16.04 - xenial</li>
			<li>14.04 - trusty</li>
		</ul>
	</div>

	<div style="float:right;width:50%;padding-right:0px;">
	<img src="assets/images/codenamePicture.png" style="border:none; background:none; width:100%"></div>
	<aside class="notes">
Here we have the cheat sheet for the distribution code names. For this class we will be using Trusty Tahr, but any of the other Ubuntu distributions are compatible with NGINX

IT’S VERY IMPORTANT not to skip ahead and just type in sudo apt-get install nginx. We need to first add these distribution urls to update our source locaiton for our apt utility 
THEN we run sudo-apt get update command to update your apt sources with the new distribution urls. Otherwise they won't be picked up and you end up with the outdated Ubuntu distribution of NGINX

	</aside>
</section>

<section>
	<h3>Install: <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 60px;">apt-get</span></pre></h3>
	<pre><code class="linux" data-trim contenteditable>
sudo apt-get update
sudo apt-get install nginx
	</code></pre>
	<aside class="notes">
		<ul>
			<li>sudo apt-get update (updates the apt-key repository based on the codename reference we just put in).</li>
<li>sudo apt-get install nginx</li>
</ul>

	</aside>
</section>

<section>
	<h3>Check Installation</h3>
	<p>NGINX will run on port 80 by default</p>
	<img src="assets/images/welcomeScreen.png" style="border:none; background:none; width:100%">
	<aside class="notes">
NGINX runs on port 80 by default.
To test this open up a browser and enter your machine url.
If NGINX fails, or you receive an HTTP response error, it’s more than likely that something else is running on port 80. So check your error logs using tail to see what’s going on.
Open up a browser, put in your machine URL, test landing page.

If NGINX fails to start up, you most likely have Apache or another program running on port 80 already

	</aside>
</section>

<section>
	<h3>Location of Files</h3>
	<p>NGINX Executable</p>
	<pre><code class="linux" data-trim contenteditable>
		/usr/sbin/nginx
	</code></pre>
	<p>Configuration File</p>
	<pre><code class="linux" data-trim contenteditable>
		/etc/nginx
	</code></pre>
	<p>Log Files</p>
	<pre><code class="linux" data-trim contenteditable>
		/var/log/nginx
	</code></pre>
	<aside class="notes">
File locations are different if NGINX is built from source files

	</aside>
</section>

<section>
	<h3>Building NGINX From Source</h3>
	<p>General Steps:</p>
	<ul>
		<li>Download <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">.tar</span></pre> file</li>
		<li>Extract the archive</li>
		<li>Run the <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">.configure</span></pre> tool</li>
		<li>Add modules with various parameters using:
			<pre><code class="linux" data-trim contenteditable>
./configure --&#60;param&#62;&#61;&#60;paramValue&#62;
	</code></pre></li>
	<li>Run <pre style="display:inline; color:rgb(240,168,40);"><span style="font-size: 30px;">make &#38;&#38; sudo make install</span></pre></li>
	<aside class="notes"></aside>
</section>

<section>
	<h3>Command Reference</h3>
	<pre><code class="linux" data-trim contenteditable>
		sudo wget &#60;nginx.org/en/download link address&#62;
tar -xvf &#60;nginx_mainline_version&#62;.tar.gz
cd &#60;nginx_mainline_verison&#62;
./configure --with-http_ssl_module --with-debug --with-&#60;other_modules&#62;
make &#38;&#38; sudo make install
	</code></pre>
	<aside class="notes"></aside>
</section>

<section>
	<h3>Important Notes</h3>
	<p>Make sure to download requisite libraries PRIOR to compiling the binary</p>
	<p>Specify file paths as needed:</p>
	<ul>
		<li>--prefix=path</li>
<li>--sbin-path=path</li>
<li>--conf-path=path</li>
<li>--error-log=path</li>
<li>--http-log=path</li>
	<pre><code class="linux" data-trim contenteditable>
#Example
./configure --sbin-path=/usr/local/nginx/nginx –-conf-path=/usr/local/nginx/nginx.conf
</code></pre>
	<aside class="notes">
<p>NGINX will yell at you if you try to compile your binanry witha module that requires a dependency.</p>
<p>Also, if you don't specify the file paths, NGINX will use the default prefix</p>
<p>Here is a list of the paths where various files are stored:</p>
<ul>

<li>--prefix=path - defines a directory that will keep server files. This same directory will also be used for all relative paths set by configure (except for paths to libraries sources) and in the nginx.conf configuration file. It is set to the /usr/local/nginx directory by default.</li>
<li>--sbin-path=path - sets the name of an nginx executable file. This name is used only during installation. By default the file is named prefix/sbin/nginx.</li>
<li>--conf-path=path — sets the name of an nginx.conf configuration file. If needs be, nginx can always be started with a different configuration file, by specifying it in the command-line parameter -c file. By default the file is named prefix/conf/nginx.conf.</li>
<li>--pid-path=path — sets the name of an nginx.pid file that will store the process ID of the main process. After installation, the file name can always be changed in the nginx.conf configuration file using the pid directive. By default the file is named prefix/logs/nginx.pid.</li>
<li>--error-log-path=path — sets the name of the primary error, warnings, and diagnostic file. After installation, the file name can always be changed in the nginx.conf configuration file using the error_log directive. By default the file is named prefix/logs/error.log. The special "stderr" value tells nginx to log pre-configuration messages to the standard error.</li>
<li>--http-log-path=path — sets the name of the primary request log file of the HTTP server. After installation, the file name can always be changed in the nginx.conf configuration file using the access_log directive. By default the file is named prefix/logs/access.log.</li>
</ul>

	</aside>
</section>


                 <!--Next Section-->
		<section data-background="rgb(20, 149, 62)">
                  <h2>Additional Resources</h2>
                 </section>

		<section>
                  <h3>Further Information</h3>
                  <li><a href="https://nginx.org/en/docs/" target="_blank">NGINX Documentation</a></li>
                  <li><a href="https://www.nginx.com/resources/admin-guide/" target="_blank">NGINX Admin Guides</a></li>
                  <li><a href="https://www.nginx.com/blog/" target="_blank">NGINX Blog</a></li>
                  <aside class="notes"></aside>
                 </section>

                 <section>
                   <h3>Q&A</h3>
                   <li><a href="http://www.surveygizmo.com/s3/3217548/NGINX-CORE-Survey" target="_blank">Survey!</a></li>
                   <li>Sales: <a href="mailto:nginx-inquiries@nginx.com" target="_top">nginx-inquiries@nginx.com</a></li>
                   <aside class="notes"></aside>
                 </section>
		</div>
	  </div>
	  
      <script src="lib/js/jquery-2.2.4.min.js"></script>
      <script src="lib/js/head.min.js"></script>
	  <script src="js/reveal.js"></script>

	  <script>

			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
            //width: 1200,


            controls: true,
				progress: true,
				history: true,
				center: true,
                slideNumber: true,
				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
          			{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: 'lib/js/jquery-2.2.4.min.js'},
                    { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'plugin/external/external.js', condition: function() { return !!document.querySelector( '[data-external]' ); } },
                    { src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

            Reveal.addEventListener( 'slidechanged', function( event ) {
//            console.log(event.currentSlide.getAttribute("data-state"))
// if we're on a lab slide, unhide the lab image, otherwise hide it.


            if(event.currentSlide.getAttribute("data-state") === "lab"){
                //document.getElementById("lab_pic").style.visibility="visible";


            if(document.getElementById("lab_pic").style.visibility=="visible"){
                document.getElementById("lab_pic").style.visibility="visible";
            }else{
      $("#lab_pic").css({opacity: 0.0, visibility: "visible"}).animate({opacity: 1}, 200);
            }

            }else{
               //(document.getElementById("lab_pic").style.visibility=="hidden";
               $("#lab_pic").css({opacity: 1.0, visibility: "hidden"}).animate({opacity: 0}, 200);
            }

            } );

		</script>

	</body>
</html>
